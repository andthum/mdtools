#!/usr/bin/env python3

# This file is part of MDTools.
# Copyright (C) 2021-2023  The MDTools Development Team and all
# contributors listed in the file AUTHORS.rst
#
# MDTools is free software: you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation, either version 3 of the License, or (at your
# option) any later version.
#
# MDTools is distributed in the hope that it will be useful, but WITHOUT
# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
# for more details.
#
# You should have received a copy of the GNU General Public License
# along with MDTools.  If not, see <http://www.gnu.org/licenses/>.


r"""
Compare state lifetimes calculated from a discrete trajectory using
different methods.

.. note::

    The term "remain probability" refers to the intermittent or
    continuous autocorrelation function of the existence/lifetime
    operator.  These autocorrelation functions are frequently used in
    the molecular dynamics literature as estimates for the survival
    function of hydrogen (and other) bonds.

Options
-------
--dtrj
    Name of the file containing the discrete trajectory.  The discrete
    trajectory must be stored as :class:`numpy.ndarray` either in a
    binary NumPy |npy_file| or in a (compressed) NumPy |npz_archive|.
    See :func:`mdtools.file_handler.load_dtrj` for more information
    about the requirements for the input file.
--rp
    Name of the file containing the remain probabilities for each state
    as generated by
    :mod:`scripts.discretization.state_lifetime_discrete`.
--km
    Name of the file containing the Kaplan-Meier estimate of the
    survival function for each state as generated by
    :mod:`scripts.discretization.kaplan_meier_discrete`.
--km-var
    Name of the file containing the variance of the Kaplan-Meier
    estimate of the survival function for each state as generated by
    :mod:`scripts.discretization.kaplan_meier_discrete`.
--param
    File containing the parameters that were used to generate the
    artificial discrete trajectory as created by
    :mod:`misc.dtrj_lifetimes.generate_dtrj.py` (optional).  If
    provided, the true lifetimes are also plotted.
-o
    Output filename pattern.
--int-thresh
    Only calculate the lifetime by directly integrating the estimated
    survival function if the survival function decays below the given
    threshold.  Default: ``0.01``.
--end-fit
    End time for fitting the estimated survival function (in trajectory
    steps).  This is inclusive, i.e. the time given here is still
    included in the fit.  If ``None``, the fit ends at 90% of the lag
    times.  Default: ``None``.
--stop-fit
    Stop fitting the estimated survival function as soon as it falls
    below the given value.  The fitting is stopped by whatever happens
    earlier: \--end-fit or \--stop-fit.  Default: ``0.01``.
--time-conv
    Time conversion factor.  Multiply times by this factor.  Default:
    ``1``.

See Also
--------
:mod:`misc.dtrj_lifetimes.generate_dtrj` :
    Generate an artificial discrete trajectory with a given number of
    states with a given lifetime distribution

Notes
-----
.. code-block:: bash

    for dtrj in *.npz; do
        fname="${dtrj::-4}"
        python3 compare_dtrj_lifetime_methods.py \
            --dtrj "${dtrj}" \
            --rp "${fname}_state_lifetime_discrete_continuous.txt.gz" \
            --km "${fname}_kaplan_meier_discrete_sf.txt.gz" \
            --km-var "${fname}_kaplan_meier_discrete_var.txt.gz" \
            --param "${fname}_param.txt.gz" \
            -o "${fname}_compare_dtrj_lifetime_methods"
    done

"""


__author__ = "Andreas Thum"


# Standard libraries
import argparse
import os
import sys
import warnings
from datetime import datetime, timedelta

# Third-party libraries
import matplotlib.pyplot as plt
import numpy as np
import psutil
from matplotlib.backends.backend_pdf import PdfPages
from matplotlib.ticker import MaxNLocator
from scipy import stats

# First-party libraries
import mdtools as mdt
import mdtools.plot as mdtplt  # Load MDTools plot style  # noqa: F401


def read_sf_from_file(
    fname, fname_var=None, time_conv=1, n_frames_check=None, states_check=None
):
    """
    Read the survival function for each state from file.

    Parameters
    ----------
    fname : str or bytes or os.PathLike
        Name of the file containing the survival function for each
        state.  The file must contain a data matrix where the first row
        contains the state indices, the first column contains the lag
        times and the remaining matrix elements contain the
        corresponding values of the survival function.  Such files are
        e.g. generated by
        :mod:`scripts.discretization.state_lifetime_discrete` or
        :mod:`scripts.discretization.kaplan_meier_discrete`.
    fname_var : str or bytes or os.PathLike or None, optional
        Optional name of the file containing the variance of the
        survival function.  The file must have the same format as the
        first one.
    time_conv : scalar, optional
        Time conversion factor.  All lag times read from the input file
        are multiplied by this factor.
    n_frames_check : int or None, optional
        Number of expected frames.  If provided, the lag times (in
        trajectory steps) that were read from the input file will be
        checked against the lag times that are to be expected from the
        given number of frames.
    states_check : array_like or None, optional
        Expected state indices.  If provided, the state indices that
        were read from the input file are checked against the provided
        state indices.

    Returns
    -------
    surv_funcs : numpy.ndarray
        Array of shape ``(t, s)`` where ``t`` is the number of lag times
        and ``s`` is the number of different states.  The ij-th element
        of `surv_funcs` is the value of the survival function of state
        j after a lag time of i frames.
    surv_funcs_var : numpy.ndarray
        Array of the same shape as `surv_funcs` containing the variance
        of the survival function.  Only returned if `fname_var` was
        provided.
    times : numpy.ndarray
        Array of shape ``(t,)`` containing the corresponding lag times.
    states : numpy.ndarray
        Array of shape ``(s,)`` containing the corresponding state
        indices.

    Raises
    ------
    ValueError :
        If a value of `surv_funcs` lies outside the interval [0, 1]; or
        if the lag times that were read from the input file are not
        equal to the expected lag times; or
        if the state indices that were read from the input file are not
        equal to the given state indices.
    """
    surv_funcs = np.loadtxt(fname)
    states = surv_funcs[0, 1:]  # State indices.
    times = surv_funcs[1:, 0]  # Lag times in trajectory steps.
    surv_funcs = surv_funcs[1:, 1:]  # Survival functions for each state
    if np.any(surv_funcs < 0) or np.any(surv_funcs > 1):
        raise ValueError(
            "Some survival function values lie outside the interval [0, 1]."
            "  Input file: {}".format(fname)
        )
    if n_frames_check is not None and not np.array_equal(
        times, np.arange(n_frames_check)
    ):
        raise ValueError(
            "`times` != `np.arange(n_frames_check)`.  Input file:"
            " {}".format(n_frames_check)
        )
    times *= time_conv  # Converted lag times.
    if np.any(np.modf(states)[0] != 0):
        raise ValueError(
            "Some state indices are not integers but floats.  `states` ="
            " {}.  Input file: {}".format(states, fname)
        )
    states = states.astype(np.int64)
    if states_check is not None and not np.array_equal(states, states_check):
        raise ValueError(
            "`states` ({}) != `states_check` ({}).  Input file:"
            " {}".format(states, states_check, fname)
        )

    if fname_var is not None:
        surv_funcs_var, times_var, states_var = read_sf_from_file(
            fname=fname_var,
            fname_var=None,
            time_conv=time_conv,
            n_frames_check=n_frames_check,
            states_check=states_check,
        )
        if surv_funcs_var.shape != surv_funcs.shape:
            raise ValueError(
                "`surv_funcs_var.shape` ({}) != `surv_funcs.shape` ({})."
                "  Input file: ({})".format(
                    surv_funcs_var.shape, surv_funcs.shape, fname_var
                )
            )
        if not np.allclose(times_var, times, rtol=0):
            raise ValueError(
                "`times_var` != `times`.  Input file: {}".format(fname_var)
            )
        if not np.array_equal(states_var, states):
            raise ValueError(
                "`states_var` != `states`.  Input file: {}".format(fname_var)
            )
        return surv_funcs, surv_funcs_var, times, states
    else:
        return surv_funcs, times, states


def dist_characs(a, axis=-1, n_moms=4):
    """
    Estimate distribution characteristics from a given sample.

    Parameters
    ----------
    a : array_like
        Array of samples.
    axis : int, optional
        The axis along which to compute the distribution
        characteristics.
    n_moms : int, optional
        Number of raw moments to calculate.

    Returns
    -------
    characs : numpy.ndarray
        Array of shape ``(11 + n_moms-1, )`` containing the following
        distribution characteristics:

            1. Sample mean (unbiased 1st raw moment)
            2. Uncertainty of the sample mean (standard error)
            3. Corrected sample standard deviation
            4. Corrected coefficient of variation
            5. Unbiased sample skewness (Fisher)
            6. Unbiased sample excess kurtosis (according to Fisher)
            7. Sample median
            8. Non-parametric skewness
            9. 2nd raw moment (biased estimate)
            10. 3rd raw moment (biased estimate)
            11. 4th raw moment (biased estimate)
            12. Sample minimum
            13. Sample maximum
            14. Number of samples

        The number of calculated raw moments depends on `n_moms`.  The
        first raw moment (mean) is always calculated.
    """
    a = np.asarray(a)
    nobs, min_max, mean, var, skew, kurt = stats.describe(
        a, axis=axis, ddof=1, bias=False
    )
    std = np.sqrt(var)
    cv = std / mean
    median = np.median(a, axis=axis)
    skew_non_param = np.divide((mean - median), std)
    raw_moments = [np.mean(a**n) for n in range(2, n_moms + 1)]
    characs = np.array(
        [
            mean,  # Sample mean.
            np.divide(std, np.sqrt(nobs)),  # Uncertainty of sample mean
            std,  # Corrected sample standard deviation.
            cv,  # Corrected coefficient of variation.
            skew,  # Unbiased sample skewness (Fisher).
            kurt,  # Unbiased sample excess kurtosis (Fisher).
            median,  # Median of the sample.
            skew_non_param,  # Non-parametric skewness.
            *raw_moments,  # 2nd to 4th raw moment (biased).
            *min_max,  # Minimum and maximum value of the sample.
            nobs,  # Number of observations (sample points).
        ]
    )
    return characs


def count_method(
    dtrj, uncensored=False, n_moms=4, time_conv=1, states_check=None
):
    """
    Estimate characteristics of the underlying lifetime distribution
    from a sample of lifetimes.

    Take a discrete trajectory and count the number of frames that a
    given compound stays in a given state.  Estimate characteristics of
    the underlying lifetime distribution from the obtained sample.

    Parameters
    ----------
    dtrj : array_like
        The discrete trajectory.  Array of shape ``(n, f)``, where ``n``
        is the number of compounds and ``f`` is the number of frames.
        The shape can also be ``(f,)``, in which case the array is
        expanded to shape ``(1, f)``.   The elements of `dtrj` are
        interpreted as the indices of the states in which a given
        compound is at a given frame.
    uncensored : bool, optional
        If ``True`` only take into account uncensored states, i.e.
        states whose start and end lie within the trajectory.  In other
        words, discard the truncated (censored) states at the beginning
        and end of the trajectory.  For these states the start/end time
        is unknown.
    n_moms : int, optional
        Number of raw moments to calculate.
    time_conv : scalar, optional
        Time conversion factor.  All lifetimes are multiplied by this
        factor.
    states_check : array_like or None, optional
        Expected state indices.  If provided, the state indices in the
        discrete trajectory are checked against the provided state
        indices.

    Returns
    -------
    characs : numpy.ndarray
        Estimated distribution characteristics.  See
        :func:`dist_characs` for more details.
    states : numpy.ndarray
        The state indices.

    Raises
    ------
    ValueError :
        If the state indices in the given discrete trajectory are not
        contained in the given array of state indices.
    """
    lts_per_state, states = mdt.dtrj.lifetimes_per_state(
        dtrj, uncensored=uncensored, return_states=True
    )
    lts_per_state = [lts * time_conv for lts in lts_per_state]
    if states_check is not None and not np.all(np.isin(states, states_check)):
        raise ValueError(
            "`states` ({}) is not fully contained in `states_check`"
            " ({})".format(states, states_check)
        )
    if states_check is not None:
        n_states = len(states_check)
    else:
        n_states = len(states)
    characs = np.full((n_states, 10 + n_moms), np.nan, dtype=np.float64)
    characs[:, -1] = 0  # Default number of observations.
    for i, lts in enumerate(lts_per_state):
        if len(lts) == 0:
            if not uncensored:
                raise ValueError(
                    "`len(lts) == 0` although `uncensored` is False"
                )
            continue
        else:
            characs[i] = dist_characs(lts, n_moms=n_moms)
    return characs, states


def cross(y, x, f):
    r"""
    Return the `x` value where the array `f` falls below the given `y`
    value for the first time.

    If `f` never falls below the given `y` value, ``numpy.nan`` is
    returned.

    If `f` falls immediately below the given `y` value, ``0`` is
    returned.

    Parameters
    ----------
    y : scalar
        The `y` value for which to get the `x` value.
    x, f : array_like
        The `x` values and corresponding `f` values.

    Returns
    -------
    x_of_y : scalar
        The `x` value that belongs to the given `y` value.
    """
    ix_y = np.nanargmax(f <= y)
    if f[ix_y] > y:
        # `f` never falls below the given `y` value.
        return np.nan
    elif ix_y < 1:
        # `f` falls immediately below the given `y` value.
        return 0
    elif f[ix_y] == y:
        return x[ix_y]
    else:
        # Linearly interpolate between `f[ix_y]` and `f[ix_y - 1]` to
        # estimate the `x` value that belongs to the given `y` value.
        slope = f[ix_y] - f[ix_y - 1]
        slope /= x[ix_y] - x[ix_y - 1]
        intercept = f[ix_y] - slope * x[ix_y]
        return (y - intercept) / slope


def raw_moment_integrate(sf, x, n=1):
    r"""
    Calculate the :math:`n`-th raw moment through numerical integration
    of the survival function using the alternative expectation formula.
    [1]_

    .. math::

        \langle x^n \rangle =
        n \int_{-\infty}^\infty x^{n-1} S(x) \text{ d}x

    Here, :math:`S(x)` is the survival function of the probability
    density function of :math:`x`.  The integral is evaluated
    numerically using :func:`numpy.trapz`.

    Parameters
    ----------
    sf : array_like
        Values of the survival function :math:`S(x)`.
    x : array_like
        Corresponding :math:`x` values.
    n : int, optional
        Order of the moment.

    Returns
    -------
    rm_n : float
        The :math:`n`-th raw moment.

    Notes
    -----
    Values where `sf` or `x` are NaN or infinite are removed prior to
    computing the integral.

    References
    ----------
    .. [1] S. Chakraborti, F. Jardim, E. Epprecht,
        `Higher-order moments using the survival function: The
        alternative expectation formula
        <https://doi.org/10.1080/00031305.2017.1356374>`_,
        The American Statistician, 2019, 73, 2, 191-194.
    """
    valid = np.isfinite(x) & np.isfinite(sf)
    if not np.any(valid):
        warnings.warn(
            "No valid values for numerical integration", stacklevel=2
        )
        return np.nan
    if n < 1 or np.any(np.modf(n)[0] != 0):
        raise ValueError(
            "The moment order, `n` ({}), must be a positive integer".format(n)
        )
    integrand = x[valid] ** (n - 1)
    integrand *= sf[valid]
    integral = np.trapz(y=integrand, x=x[valid])
    integral *= n
    return integral


def skewness(mu2, mu3):
    r"""
    Calculate Fisher's skewness of a distribution from the second and
    third central moment.

    .. math::

        \gamma_1 = \frac{\mu_3}{\mu_2^{3/2}}

    Here, :math:`\mu_n = \langle (x - \mu)^n \rangle` is the
    :math:`n`-th central moment.

    Parameters
    ----------
    mu2, mu3 : scalar or array_like
        The second and third central moment.

    Returns
    -------
    skew : scalar or numpy.ndarray
        The skewness of the distribution.

    Notes
    -----
    If more than one input argument is an array, all arrays must be
    broadcastable.
    """
    return np.divide(mu3, np.power(mu2, 3 / 2))


def kurtosis(mu2, mu4):
    r"""
    Calculate the excess kurtosis (according to Fisher) of a
    distribution from the second and fourth central moment.

    .. math::

        \gamma_2 = \frac{\mu_4}{\mu_2^2} - 3

    Here, :math:`\mu_n = \langle (x - \mu)^n \rangle` is the
    :math:`n`-th central moment.

    Parameters
    ----------
    mu2, mu4 : scalar or array_like
        The second and fourth central moment.

    Returns
    -------
    kurt : scalar or numpy.ndarray
        The excess kurtosis of the distribution.

    Notes
    -----
    If more than one input argument is an array, all arrays must be
    broadcastable.
    """
    return np.divide(mu4, np.power(mu2, 2)) - 3


def integral_method(surv_funcs, times, n_moms=4, int_thresh=0.01):
    r"""
    Estimate characteristics of the underlying lifetime distribution by
    numerically integrating/evaluating the survival function.

    Take a survival function and calculate the raw moments of the
    underlying lifetime distribution by numerically integrating the
    survival function according to the alternative expectation formula
    (see :func:`raw_moment_integrate` for more details).  The standard
    deviation, skewness and excess kurtosis are calculated from the raw
    moments.  The median is estimated as the lag time at which the
    survival function decays below 0.5.

    Parameters
    ----------
    surv_funcs : array_like
        Array of shape ``(t, s)`` where ``t`` is the number of lag times
        and ``s`` is the number of different states.  The ij-th element
        of `surv_funcs` is the value of the survival function of state
        j after a lag time of i frames.
    times : array_like
        Array of shape ``(t,)`` containing the corresponding lag times.
    n_moms : int, optional
        Number of moments to calculate.  Must be greater than zero.
    int_thresh : float, optional
        Only calculate raw moments by numerical integration if the
        survival function decays below the given threshold.

    Returns
    -------
    characs : numpy.ndarray
        Array of shape ``(7 + n_moms-1, )`` containing the following
        distribution characteristics:

            1. Mean (1st raw moment)
            2. Standard deviation
            3. Coefficient of variation
            4. Skewness (Fisher)
            5. Excess kurtosis (according to Fisher)
            6. Median
            7. Non-parametric skewness
            8. 2nd raw moment
            9. 3rd raw moment
            10. 4th raw moment

        The number of calculated raw moments depends on `n_moms`.  The
        first raw moment (mean) is always calculated.
    """
    surv_funcs = np.asarray(surv_funcs)
    times = np.asarray(times)
    if surv_funcs.ndim != 2:
        raise ValueError(
            "`surv_funcs` must be 2-dimensional but is"
            " {}-dimensional".format(surv_funcs.ndim)
        )
    if times.shape != surv_funcs.shape[:1]:
        raise ValueError(
            "`times.shape` ({}) != `surv_funcs.shape[:1]`"
            " ({})".format(times.shape, surv_funcs.shape[:1])
        )
    if n_moms < 1:
        raise ValueError(
            "`n_moms` ({}) must be greater than zero".format(n_moms)
        )

    n_frames, n_states = surv_funcs.shape
    characs = np.full((n_states, 6 + n_moms), np.nan, dtype=np.float64)
    for i, sf in enumerate(surv_funcs.T):
        raw_moms = np.full(n_moms, np.nan, dtype=np.float64)
        cen_moms = np.full_like(raw_moms, np.nan)
        if np.any(sf <= int_thresh):
            # Only calculate the moments by numerical integration if the
            # survival function decays below the given threshold.
            for n in range(len(raw_moms)):
                raw_moms[n] = raw_moment_integrate(sf=sf, x=times, n=n + 1)
                cen_moms[n] = mdt.stats.moment_raw2cen(raw_moms[: n + 1])
        skew = skewness(mu2=cen_moms[1], mu3=cen_moms[2])
        kurt = kurtosis(mu2=cen_moms[1], mu4=cen_moms[3])
        std = np.sqrt(cen_moms[1])
        cv = std / raw_moms[0]
        median = cross(y=0.5, x=times, f=sf)
        skew_non_param = np.divide((raw_moms[0] - median), std)
        characs[i] = np.array(
            [
                raw_moms[0],  # Mean.
                std,  # Standard deviation.
                cv,  # Coefficient of variation.
                skew,  # Skewness (Fisher).
                kurt,  # Excess kurtosis (Fisher).
                median,  # Median
                skew_non_param,  # Non-parametric skewness.
                *raw_moms[1:],  # 2nd to `n_moms`-th raw moment.
            ]
        )
    return characs


def get_fit_region(surv_funcs, times, end_fit=None, stop_fit=0.01):
    """
    Get the start and end points of the region within which to fit the
    survival function.

    Parameters
    ----------
    surv_funcs : array_like
        Array of shape ``(t, s)`` where ``t`` is the number of lag times
        and ``s`` is the number of different states.  The ij-th element
        of `surv_funcs` is the value of the survival function of state
        j after a lag time of i frames.
    times : array_like
        Array of shape ``(t,)`` containing the corresponding lag times.
    end_fit : float or None, optional
        End time for fitting.  If None, the fit ends at 90% of the lag
        times.
    stop_fit : float, optional
        Stop fitting the survival function as soon as it falls below the
        given value.  The fitting is stopped by whatever happens
        earlier: `end_fit` or `stop_fit`.

    Returns
    -------
    fit_start_ix, fit_stop_ix : numpy.ndarray
        1-dimensional arrays containing for each state the index of the
        start (inclusive) and end point (exclusive) of the region to
        fit.
    """
    surv_funcs = np.asarray(surv_funcs)
    times = np.asarray(times)
    if surv_funcs.ndim != 2:
        raise ValueError(
            "`surv_funcs` must be 2-dimensional but is"
            " {}-dimensional".format(surv_funcs.ndim)
        )
    if times.shape != surv_funcs.shape[:1]:
        raise ValueError(
            "`times.shape` ({}) != `surv_funcs.shape[:1]`"
            " ({})".format(times.shape, surv_funcs.shape[:1])
        )

    if end_fit is None:
        end_fit_ix = int(0.9 * len(times))
    else:
        _, end_fit_ix = mdt.nph.find_nearest(times, end_fit, return_index=True)
    end_fit_ix += 1  # Make `end_fit_ix` inclusive.

    fit_start_ix = np.zeros(surv_funcs.shape[1], dtype=np.uint32)  # Inclusive.
    fit_stop_ix = np.zeros(surv_funcs.shape[1], dtype=np.uint32)  # Exclusive.
    for i, sf in enumerate(surv_funcs.T):
        stop_fit_ix = np.nanargmax(sf < stop_fit)
        if sf[stop_fit_ix] >= stop_fit:
            # The remain probability never falls below `stop_fit`.
            stop_fit_ix = len(sf)
        elif stop_fit_ix < 2:
            # The remain probability immediately falls below `stop_fit`.
            stop_fit_ix = 2
        fit_stop_ix[i] = min(end_fit_ix, stop_fit_ix)
    return fit_start_ix, fit_stop_ix


def fit_goodness(data, fit):
    """
    Calculate quantities to assess the goodness of a fit.

    Parameters
    ----------
    data : array_like
        The true data.
    fit : array_like
        Array of the same shape as `data` containing the corresponding
        fit/model values.

    Returns
    -------
    r2 : scalar
        (Pseudo) coefficient of determination.  See
        https://www.r-bloggers.com/2021/03/the-r-squared-and-nonlinear-regression-a-difficult-marriage.
    rmse : scalar
        The root-mean-square error, also known as root-mean-square
        residuals.
    """
    data = np.asarray(data)
    fit = np.asarray(fit)
    if fit.shape != data.shape:
        raise ValueError(
            "`fit.shape` ({}) != `data.shape`"
            " ({})".format(fit.shape, data.shape)
        )

    # Residual sum of squares.
    ss_res = np.sum((data - fit) ** 2)
    # Root-mean-square error / root-mean-square residuals.
    rmse = np.sqrt(np.divide(ss_res, len(fit)))
    # Total sum of squares.
    ss_tot = np.sum((data - np.mean(data)) ** 2)
    # (Pseudo) coefficient of determination (R^2).
    r2 = 1 - np.divide(ss_res, ss_tot)
    return r2, rmse


def weibull_fit_method(
    surv_funcs,
    times,
    fit_start,
    fit_stop,
    surv_funcs_var=None,
    n_moms=4,
    fit_method="trf",
):
    r"""
    Estimate characteristics of the underlying lifetime distribution
    assuming a Weibull distribution.

    Take a survival function and fit it with the survival function of a
    Weibull distribution.  Characteristics of the underlying lifetime
    distribution are thus described by characteristics of the fitted
    Weibull distribution.

    Parameters
    ----------
    surv_funcs : array_like
        Array of shape ``(t, s)`` where ``t`` is the number of lag times
        and ``s`` is the number of different states.  The ij-th element
        of `surv_funcs` is the value of the survival function of state
        j after a lag time of i frames.
    times : array_like
        Array of shape ``(t,)`` containing the corresponding lag times.
    fit_start_ix, fit_stop_ix : numpy.ndarray
        1-dimensional arrays containing for each state the index of the
        start (inclusive) and end point (exclusive) of the region to
        fit.
    surv_funcs_var : array_like or None, optional
        Array of the same shape as `surv_funcs` containing the variance
        of the survival function.
    n_moms : int, optional
        Number of moments to calculate.  Must be greater than zero.
    fit_method : str, optional
        Fit method of :func:`scipy.optimize.curve_fit` to use for
        fitting the survival function.  See there for possible options.

    Returns
    -------
    characs : numpy.ndarray
        Array of shape ``(7 + n_moms-1, )`` containing the following
        distribution characteristics:

            1. Mean (1st raw moment)
            2. Standard deviation
            3. Coefficient of variation
            4. Skewness (Fisher)
            5. Excess kurtosis (according to Fisher)
            6. Median
            7. Non-parametric skewness
            8. 2nd raw moment
            9. 3rd raw moment
            10. 4th raw moment

        The number of calculated raw moments depends on `n_moms`.  The
        first raw moment (mean) is always calculated.
    fit_quality : numpy.ndarray
        Array that contains quantities to assess the goodness of a fit.
        See :func:`fit_goodness` for details about the calculated
        quantities.
    popt : numpy.ndarray
        Optimal values for the fit parameters so that the sum of the
        squared residuals is minimized.  The first element of `popt` is
        the optimal :math:`\tau_0` value, the second element is the
        optimal :math:`\beta` value.
    perr : numpy.ndarray
        Standard deviation of the optimal parameters.

    See Also
    --------
    :func:`mdtools.fit.fit_kww` :
        The function that is used to fit the survival functions.

    Notes
    -----
    The probability distribution function of the Weibull distribution is
    given by

    .. math::

        f(t) =
        \frac{\beta}{\tau_0}
        \left( \frac{t}{\tau_0} \right)^{\beta - 1}
        \exp{\left[ \left( -\frac{t}{\tau_0} \right)^\beta \right]}

    It is a special form of the generalized gamma distribution with
    :math:`\delta = \beta`.

    .. math::

        f(t) =
        \frac{1}{\Gamma\left( \frac{\delta}{\beta} \right)}
        \frac{\beta}{\tau_0}
        \left( \frac{t}{\tau_0} \right)^{\delta - 1}
        \exp{\left[ \left( -\frac{t}{\tau_0} \right)^\beta \right]}

    If :math:`\beta = 1`, the Weibull distribution reduces to the
    exponential distribution.

    The survival function of the Weibull distribution is a stretched
    exponential, also known as Kohlrausch or Kohlrausch-Williams-Watts
    (KWW) function:

    .. math::

        S(t) = \exp\left[ -\left(\frac{t}{\tau_0})^\beta \right) \right]

    The :math:`n`-th raw moment of the Weibull distribution is

    .. math::

        \langle t^n \rangle = \tau_0^n \Gamma(1 + \frac{n}{\beta})

    The median of the Weibull distribution is

    .. math::

        t_med = tau_0 * \left[ \len(2) \right]^\frac{1}{\beta}

    The skewness of the Weibull distribution is

    .. math::

        \gamma_1 =
        \frac{
             2 \Gamma^3\left( 1 + \frac{1}{\beta} \right)
            -3 \Gamma  \left( 1 + \frac{1}{\beta} \right)
               \Gamma  \left( 1 + \frac{2}{\beta} \right)
            +  \Gamma  \left( 1 + \frac{3}{\beta} \right)
        }{
            \left[
                 \Gamma  \left( 1 + \frac{2}{\beta} \right)
                -\Gamma^2\left( 1 + \frac{1}{\beta} \right)
            \right]^{3/2}
        }

    The excess kurtosis (according to Fisher) of the Weibull
    distribution is

    .. math::

        \gamma_2 =
        \frac{
             -6 \Gamma^4\left( 1 + \frac{1}{\beta} \right)
            +12 \Gamma^2\left( 1 + \frac{1}{\beta} \right)
                \Gamma  \left( 1 + \frac{2}{\beta} \right)
             -3 \Gamma^2\left( 1 + \frac{2}{\beta} \right)
             -4 \Gamma  \left( 1 + \frac{1}{\beta} \right)
                \Gamma  \left( 1 + \frac{3}{\beta} \right)
             +  \Gamma  \left( 1 + \frac{4}{\beta} \right)
        }{
            \left[
                 \Gamma  \left( 1 + \frac{2}{\beta} \right) -
                -\Gamma^2\left( 1 + \frac{1}{\beta} \right)
            \right]^2
        }

    """
    surv_funcs = np.asarray(surv_funcs)
    times = np.asarray(times)
    fit_start = np.asarray(fit_start)
    fit_stop = np.asarray(fit_stop)
    if surv_funcs.ndim != 2:
        raise ValueError(
            "`surv_funcs` must be 2-dimensional but is"
            " {}-dimensional".format(surv_funcs.ndim)
        )
    if times.shape != surv_funcs.shape[:1]:
        raise ValueError(
            "`times.shape` ({}) != `surv_funcs.shape[:1]`"
            " ({})".format(times.shape, surv_funcs.shape[:1])
        )
    if fit_start.shape != surv_funcs.shape[1:]:
        raise ValueError(
            "`fit_start.shape` ({}) != `surv_funcs.shape[1:]v"
            " ({})".format(fit_start.shape, surv_funcs.shape[1:])
        )
    if fit_stop.shape != fit_start.shape:
        raise ValueError(
            "`fit_stop.shape` ({}) != `fit_start.shape`"
            " ({})".format(fit_stop.shape, fit_start.shape)
        )
    if n_moms < 1:
        raise ValueError(
            "`n_moms` ({}) must be greater than zero".format(n_moms)
        )

    if surv_funcs_var is not None:
        surv_funcs_var = np.asarray(surv_funcs_var)
        if surv_funcs_var.shape != surv_funcs.shape:
            raise ValueError(
                "`surv_funcs_var.shape` ({}) != `surv_funcs.shape`"
                " ({})".format(surv_funcs_var.shape, surv_funcs.shape)
            )

    n_frames, n_states = surv_funcs.shape
    bounds = ([0, 0], [np.inf, np.inf])
    popt = np.full((n_states, 2), np.nan, dtype=np.float64)
    perr = np.full_like(popt, np.nan)
    fit_quality = np.full((n_states, 2), np.nan, dtype=np.float64)
    characs = np.full((n_states, 6 + n_moms), np.nan, dtype=np.float64)
    for i, sf in enumerate(surv_funcs.T):
        # Do the fit.
        times_fit = times[fit_start[i] : fit_stop[i]]
        sf_fit = sf[fit_start[i] : fit_stop[i]]
        if surv_funcs_var is not None:
            sf_sd = np.sqrt(surv_funcs_var[:, i][fit_start[i] : fit_stop[i]])
        else:
            sf_sd = None
        popt[i], perr[i], valid = mdt.func.fit_kww(
            xdata=times_fit,
            ydata=sf_fit,
            ysd=sf_sd,
            return_valid=True,
            bounds=bounds,
            method=fit_method,
        )
        fit = mdt.func.kww(times_fit[valid], *popt[i])
        fit_quality[i] = np.array(fit_goodness(data=sf_fit[valid], fit=fit))
        # Calculate distribution characteristics.
        dist = stats.gengamma(
            a=1,  # delta/beta = beta/beta = 1.
            c=popt[i, 1],  # beta.
            loc=0,
            scale=popt[i, 0],  # tau0.
        )
        raw_moms = [dist.moment(n) for n in range(1, n_moms + 1)]
        var, skew, kurt = dist.stats(moments="vsk")
        std = np.sqrt(var)
        cv = std / raw_moms[0]
        median = dist.median()
        skew_non_param = np.divide((raw_moms[0] - median), std)
        characs[i] = np.array(
            [
                raw_moms[0],  # Mean.
                std,  # Standard deviation.
                cv,  # Coefficient of variation.
                skew,  # Skewness (Fisher).
                kurt,  # Excess kurtosis (Fisher).
                median,  # Median
                skew_non_param,  # Non-parametric skewness.
                *raw_moms[1:],  # 2nd to `n_moms`-th raw moment.
            ]
        )
    return characs, fit_quality, popt, perr


def burr12_fit_method(
    surv_funcs,
    times,
    fit_start,
    fit_stop,
    surv_funcs_var=None,
    n_moms=4,
    fit_method="trf",
):
    r"""
    Estimate characteristics of the underlying lifetime distribution
    assuming a Burr Type XII distribution.

    Take a survival function and fit it with the survival function of a
    Burr Type XII distribution.  Characteristics of the underlying
    lifetime distribution are thus described by characteristics of the
    fitted Burr Type XII distribution.

    Parameters
    ----------
    surv_funcs : array_like
        Array of shape ``(t, s)`` where ``t`` is the number of lag times
        and ``s`` is the number of different states.  The ij-th element
        of `surv_funcs` is the value of the survival function of state
        j after a lag time of i frames.
    times : array_like
        Array of shape ``(t,)`` containing the corresponding lag times.
    fit_start_ix, fit_stop_ix : numpy.ndarray
        1-dimensional arrays containing for each state the index of the
        start (inclusive) and end point (exclusive) of the region to
        fit.
    surv_funcs_var : array_like or None, optional
        Array of the same shape as `surv_funcs` containing the variance
        of the survival function.
    n_moms : int, optional
        Number of moments to calculate.  Must be greater than zero.
    fit_method : str, optional
        Fit method of :func:`scipy.optimize.curve_fit` to use for
        fitting the survival function.  See there for possible options.

    Returns
    -------
    characs : numpy.ndarray
        Array of shape ``(7 + n_moms-1, )`` containing the following
        distribution characteristics:

            1. Mean (1st raw moment)
            2. Standard deviation
            3. Coefficient of variation
            4. Skewness (Fisher)
            5. Excess kurtosis (according to Fisher)
            6. Median
            7. Non-parametric skewness
            8. 2nd raw moment
            9. 3rd raw moment
            10. 4th raw moment

        The number of calculated raw moments depends on `n_moms`.  The
        first raw moment (mean) is always calculated.
    fit_quality : numpy.ndarray
        Array that contains quantities to assess the goodness of a fit.
        See :func:`fit_goodness` for details about the calculated
        quantities.
    popt : numpy.ndarray
        Optimal values for the fit parameters so that the sum of the
        squared residuals is minimized.  The first element of `popt` is
        the optimal :math:`\tau_0` value, the second element is the
        optimal :math:`\beta` value, the third value is the optimal
        :math:`d` value, where :math:`d = \beta\delta` (!).
    perr : numpy.ndarray
        Standard deviation of the optimal parameters.
    popt_converted : numpy.ndarray
        Same as `popt`, but instead of :math:`d = \beta\delta`, the
        third value is :math:`\delta`.
    perr_converted : numpy.ndarray
        Standard deviation of `popt_converted`.

    See Also
    --------
    :func:`mdtools.fit.fit_burr12_sf_alt` :
        The function that is used to fit the survival functions.

    Notes
    -----
    The probability distribution function of the Burr Type XII
    distribution is given by

    .. math::

        f(t) =
        \frac{\beta \delta}{\tau_0}
        \left( \frac{t}{\tau_0} \right)^{\beta - 1}
        \frac{
            1
        }{
            \left[
                1 + \left( \frac{t}{\tau_0} \right)^\beta
            \right]^{\delta - 1}
        }

    If :math:`\delta = 1`, the Burr Type XII distribution reduces to the
    log-logistic distribution.  If :math:`\beta = 1`, the Burr Type XII
    distribution reduces to the Lomax distribution.

    The survival function of the Burr Type XII distribution is

    .. math::

        S(t) =
        \frac{
            1
        }{
            \left[
                1 + \left( \frac{t}{\tau_0} \right)^\beta
            \right]^\delta
        }

    For :math:`\beta = 1`, the survival function is also known as
    Becquerel decay.

    The :math:`n`-th raw moment of the Burr Type XII distribution is

    .. math::

        \langle t^n \rangle =
        \tau_0^n
        \frac{
            \Gamma\left( \delta - \frac{n}{\beta} \right)
            \Gamma\left( 1      + \frac{n}{\beta} \right)
        }{
            \Gamma(\delta)
        }

    Note that the n-th raw moment of the Burr Type XII distribution only
    exists if :math:`n < \beta \delta`.

    The median of the Burr Type XII distribution is

    .. math::

        t_med = \frac{1}{\left( 2^{1/\delta} - 1 \right)^(1/\beta)}

    """
    surv_funcs = np.asarray(surv_funcs)
    times = np.asarray(times)
    fit_start = np.asarray(fit_start)
    fit_stop = np.asarray(fit_stop)
    if surv_funcs.ndim != 2:
        raise ValueError(
            "`surv_funcs` must be 2-dimensional but is"
            " {}-dimensional".format(surv_funcs.ndim)
        )
    if times.shape != surv_funcs.shape[:1]:
        raise ValueError(
            "`times.shape` ({}) != `surv_funcs.shape[:1]`"
            " ({})".format(times.shape, surv_funcs.shape[:1])
        )
    if fit_start.shape != surv_funcs.shape[1:]:
        raise ValueError(
            "`fit_start.shape` ({}) != `surv_funcs.shape[1:]`"
            " ({})".format(fit_start.shape, surv_funcs.shape[1:])
        )
    if fit_stop.shape != fit_start.shape:
        raise ValueError(
            "`fit_stop.shape` ({}) != `fit_start.shape`"
            " ({})".format(fit_stop.shape, fit_start.shape)
        )
    if n_moms < 1:
        raise ValueError(
            "`n_moms` ({}) must be greater than zero".format(n_moms)
        )

    if surv_funcs_var is not None:
        surv_funcs_var = np.asarray(surv_funcs_var)
        if surv_funcs_var.shape != surv_funcs.shape:
            raise ValueError(
                "`surv_funcs_var.shape` ({}) != `surv_funcs.shape`"
                " ({})".format(surv_funcs_var.shape, surv_funcs.shape)
            )

    n_frames, n_states = surv_funcs.shape
    bounds = ([0, 0, 1 + 1e-6], [np.inf, np.inf, np.inf])
    popt = np.full((n_states, 3), np.nan, dtype=np.float64)
    perr = np.full_like(popt, np.nan)
    fit_quality = np.full((n_states, 2), np.nan, dtype=np.float64)
    characs = np.full((n_states, 6 + n_moms), np.nan, dtype=np.float64)
    for i, sf in enumerate(surv_funcs.T):
        # Do the fit.
        times_fit = times[fit_start[i] : fit_stop[i]]
        sf_fit = sf[fit_start[i] : fit_stop[i]]
        if surv_funcs_var is not None:
            sf_sd = np.sqrt(surv_funcs_var[:, i][fit_start[i] : fit_stop[i]])
        else:
            sf_sd = None
        popt[i], perr[i], valid = mdt.func.fit_burr12_sf_alt(
            xdata=times_fit,
            ydata=sf_fit,
            ysd=sf_sd,
            return_valid=True,
            bounds=bounds,
            method=fit_method,
        )
        fit = mdt.func.burr12_sf_alt(times_fit[valid], *popt[i])
        fit_quality[i] = np.array(fit_goodness(data=sf_fit[valid], fit=fit))
        # Calculate distribution characteristics.
        dist = stats.burr12(
            c=popt[i, 1],  # beta.
            d=popt[i, 2] / popt[i, 1],  # delta.
            loc=0,
            scale=popt[i, 0],  # tau0.
        )
        raw_moms = [dist.moment(n) for n in range(1, n_moms + 1)]
        var, skew, kurt = dist.stats(moments="vsk")
        std = np.sqrt(var)
        cv = std / raw_moms[0]
        median = dist.median()
        skew_non_param = np.divide((raw_moms[0] - median), std)
        characs[i] = np.array(
            [
                raw_moms[0],  # Mean.
                std,  # Standard deviation.
                cv,  # Coefficient of variation.
                skew,  # Skewness (Fisher).
                kurt,  # Excess kurtosis (Fisher).
                median,  # Median
                skew_non_param,  # Non-parametric skewness.
                *raw_moms[1:],  # 2nd to `n_moms`-th raw moment.
            ]
        )

    tau0, beta, d = popt.T
    tau0_sd, beta_sd, d_sd = perr.T
    delta = d / beta
    delta_sd = np.sqrt(  # Propagation of uncertainty.
        delta**2
        * (
            (d_sd / d) ** 2
            + (beta_sd / beta) ** 2
            - 2 * d_sd * beta_sd / (d * beta)
        )
    )
    popt_converted = np.column_stack([tau0, beta, delta])
    perr_converted = np.column_stack([tau0_sd, beta_sd, delta_sd])
    return characs, fit_quality, popt, perr, popt_converted, perr_converted


def get_ydata_min_max(ax):
    """
    Get the minimum and maximum y value of the data plotted in an
    :class:`matplotlib.axes.Axes`.

    Parameters
    ----------
    ax : matplotlib.axes.Axes
        The :class:`~matplotlib.axes.Axes` from which to get the data.

    Returns
    -------
    yd_min, yd_max : numpy.ndarray
        Array of minimum and maximum values of the y data plotted in the
        given :class:`~matplotlib.axes.Axes`.  Each value in the array
        corresponds to one plotted :class:`matplotlib.lines.Line2D` in
        the :class:`~matplotlib.axes.Axes`.
    """
    ydata = [line.get_ydata() for line in ax.get_lines()]
    yd_min, yd_max = [], []
    for yd in ydata:
        if isinstance(yd, np.ndarray) and np.any(yd > 0):
            yd_min.append(np.min(yd[yd > 0]))
            yd_max.append(np.max(yd[yd > 0]))
    yd_min, yd_max = np.array(yd_min), np.array(yd_max)
    return yd_min, yd_max


if __name__ == "__main__":  # noqa: C901
    timer_tot = datetime.now()
    proc = psutil.Process()
    proc.cpu_percent()  # Initiate monitoring of CPU usage.
    parser = argparse.ArgumentParser(
        # The description should only contain the short summary from the
        # docstring and a reference to the documentation.
        description=(
            "Compare state lifetimes calculated from a discrete trajectory"
            " using different methods"
        )
    )
    parser.add_argument(
        "--dtrj",
        dest="INFILE_DTRJ",
        type=str,
        required=True,
        help=(
            "File containing the discrete trajectory stored as numpy.ndarray"
            " in the binary .npy format or as .npz archive."
        ),
    )
    parser.add_argument(
        "--rp",
        dest="INFILE_RP",
        type=str,
        required=True,
        help=(
            "Name of the file containing the remain probabilities for each"
            " state."
        ),
    )
    parser.add_argument(
        "--km",
        dest="INFILE_KM",
        type=str,
        required=True,
        help=(
            "Name of the file containing the Kaplan-Meier estimate of the"
            " survival function for each state."
        ),
    )
    parser.add_argument(
        "--km-var",
        dest="INFILE_KM_VAR",
        type=str,
        required=True,
        help=(
            "Name of the file containing the variance of the Kaplan-Meier"
            " estimate of the survival function for each state"
        ),
    )
    parser.add_argument(
        "--param",
        dest="INFILE_PARAM",
        type=str,
        required=False,
        default=None,
        help=(
            "File containing the parameters that were used to generate the"
            " artificial discrete trajectory (optional)."
        ),
    )
    parser.add_argument(
        "-o",
        dest="OUTFILE",
        type=str,
        required=True,
        help="Output filename pattern.",
    )
    parser.add_argument(
        "--int-thresh",
        dest="INT_THRESH",
        type=float,
        required=False,
        default=0.01,
        help=(
            "Only calculate the lifetime by directly integrating the estimated"
            " survival function if the survival function decays below the"
            " given threshold.  Default:  %(default)s."
        ),
    )
    parser.add_argument(
        "--end-fit",
        dest="ENDFIT",
        type=float,
        required=False,
        default=None,
        help=(
            "End time for fitting the survival function in trajectory steps"
            " (inclusive).  If None, the fit ends at 90%% of the lag times."
            "  Default: %(default)s."
        ),
    )
    parser.add_argument(
        "--stop-fit",
        dest="STOPFIT",
        type=float,
        required=False,
        default=0.01,
        help=(
            "Stop fitting the survival function as soon as it falls below the"
            " given value.  The fitting is stopped by whatever happens"
            " earlier: --end-fit or --stop-fit.  Default: %(default)s."
        ),
    )
    parser.add_argument(
        "--time-conv",
        dest="TIME_CONV",
        type=float,
        required=False,
        default=1,
        help="Time conversion factor.  Default: %(default)s.",
    )
    args = parser.parse_args()
    print(mdt.rti.run_time_info_str())

    # Number of moments to calculate.  For calculating the skewness, the
    # 2nd and 3rd (central) moments are required, for the kurtosis the
    # 2nd and 4th (central) moments are required.
    n_moms = 4
    # Fit method of `scipy.optimize.curve_fit` to use for all fits.
    fit_method = "trf"

    ####################################################################
    print("\n")
    print("Calculating lifetimes directly from `dtrj`...")
    timer = datetime.now()
    dtrj = mdt.fh.load_dtrj(args.INFILE_DTRJ)
    n_frames = dtrj.shape[1]
    # Method 1: Censored counting.
    lts_cnt_cen_characs, states = count_method(
        dtrj, uncensored=False, time_conv=args.TIME_CONV, states_check=None
    )
    n_states = len(states)
    # Method 2: Uncensored counting.
    lts_cnt_unc_characs, _states = count_method(
        dtrj, uncensored=True, time_conv=args.TIME_CONV, states_check=states
    )
    del _states
    # Method 3: Calculate the transition rate as the number of
    # transitions leading out of a given state divided by the number of
    # frames that compounds have spent in this state.  The average
    # lifetime is calculated as the inverse transition rate.
    rates, states_k = mdt.dtrj.trans_rate_per_state(dtrj, return_states=True)
    lts_k = args.TIME_CONV / rates
    if not np.array_equal(states_k, states):
        raise ValueError(
            "`states_k` ({}) != `states` ({})".format(states_k, states)
        )
    del dtrj, rates, states_k
    print("Elapsed time:         {}".format(datetime.now() - timer))
    print("Current memory usage: {:.2f} MiB".format(mdt.rti.mem_usage(proc)))
    ####################################################################

    ####################################################################
    print("\n")
    print("Calculating lifetimes from the remain probability...")
    timer = datetime.now()
    # Read remain probabilities from file.
    remain_probs, times, _states = read_sf_from_file(
        args.INFILE_RP,
        time_conv=args.TIME_CONV,
        n_frames_check=n_frames,
        states_check=states,
    )
    del _states
    # Method 4: Numerical integration of the remain probability.
    lts_rp_int_characs = integral_method(
        remain_probs, times, n_moms=n_moms, int_thresh=args.INT_THRESH
    )
    # Get fit region for fitting methods.
    fit_start_rp, fit_stop_rp = get_fit_region(
        remain_probs, times, end_fit=args.ENDFIT, stop_fit=args.STOPFIT
    )
    # Method 5: Weibull fit of the remain probability.
    (
        lts_rp_wbl_characs,
        lts_rp_wbl_fit_goodness,
        popt_rp_wbl,
        perr_rp_wbl,
    ) = weibull_fit_method(
        remain_probs,
        times,
        fit_start=fit_start_rp,
        fit_stop=fit_stop_rp,
        n_moms=n_moms,
        fit_method=fit_method,
    )
    tau0_rp_wbl, beta_rp_wbl = popt_rp_wbl.T
    tau0_rp_wbl_sd, beta_rp_wbl_sd = perr_rp_wbl.T
    # Method 6: Burr Type XII fit of the remain probability.
    (
        lts_rp_brr_characs,
        lts_rp_brr_fit_goodness,
        popt_rp_brr,
        perr_rp_brr,
        popt_conv_rp_brr,
        perr_conv_rp_brr,
    ) = burr12_fit_method(
        remain_probs,
        times,
        fit_start=fit_start_rp,
        fit_stop=fit_stop_rp,
        n_moms=n_moms,
        fit_method=fit_method,
    )
    tau0_rp_brr, beta_rp_brr, delta_rp_brr = popt_conv_rp_brr.T
    tau0_rp_brr_sd, beta_rp_brr_sd, delta_rp_brr_sd = perr_conv_rp_brr.T
    print("Elapsed time:         {}".format(datetime.now() - timer))
    print("Current memory usage: {:.2f} MiB".format(mdt.rti.mem_usage(proc)))
    ####################################################################

    ####################################################################
    print("\n")
    print("Calculating lifetimes from the Kaplan-Meier estimator...")
    timer = datetime.now()
    # TODO
    # Read Kaplan-Meier survival functions from file.
    km_surv_funcs, km_surv_funcs_var, times, _states = read_sf_from_file(
        args.INFILE_KM,
        fname_var=args.INFILE_KM_VAR,
        time_conv=args.TIME_CONV,
        n_frames_check=n_frames,
        states_check=states,
    )
    del _states
    # Method 7: Numerical integration of the Kaplan-Meier estimator.
    lts_km_int_characs = integral_method(
        km_surv_funcs, times, n_moms=n_moms, int_thresh=args.INT_THRESH
    )
    # Get fit region for fitting methods.
    fit_start_km, fit_stop_km = get_fit_region(
        km_surv_funcs, times, end_fit=args.ENDFIT, stop_fit=args.STOPFIT
    )
    # Method 8: Weibull fit of the Kaplan-Meier estimator.
    (
        lts_km_wbl_characs,
        lts_km_wbl_fit_goodness,
        popt_km_wbl,
        perr_km_wbl,
    ) = weibull_fit_method(
        remain_probs,
        times,
        fit_start=fit_start_km,
        fit_stop=fit_stop_km,
        surv_funcs_var=km_surv_funcs_var,
        n_moms=n_moms,
        fit_method=fit_method,
    )
    tau0_km_wbl, beta_km_wbl = popt_km_wbl.T
    tau0_km_wbl_sd, beta_km_wbl_sd = perr_km_wbl.T
    # Method 9: Burr Type XII fit of the Kaplan-Meier estimator.
    (
        lts_km_brr_characs,
        lts_km_brr_fit_goodness,
        popt_km_brr,
        perr_km_brr,
        popt_conv_km_brr,
        perr_conv_km_brr,
    ) = burr12_fit_method(
        remain_probs,
        times,
        fit_start=fit_start_km,
        fit_stop=fit_stop_km,
        surv_funcs_var=km_surv_funcs_var,
        n_moms=n_moms,
        fit_method=fit_method,
    )
    tau0_km_brr, beta_km_brr, delta_km_brr = popt_conv_km_brr.T
    tau0_km_brr_sd, beta_km_brr_sd, delta_km_brr_sd = perr_conv_km_brr.T
    print("Elapsed time:         {}".format(datetime.now() - timer))
    print("Current memory usage: {:.2f} MiB".format(mdt.rti.mem_usage(proc)))
    ####################################################################

    ####################################################################
    if args.INFILE_PARAM is not None:
        print("\n")
        print("Reading true lifetimes from parameters file...")
        params = np.loadtxt(args.INFILE_PARAM, usecols=np.arange(4))
        states_true = params[:, 0]
        if not np.all(np.isin(states, states_true)):
            raise ValueError(
                "`states` ({}) is not fully contained in `states_true`"
                " ({})".format(states, states_true)
            )
        del states_true
        params = params[states]
        # Parameters of the true lifetime distribution.
        beta_true, delta_true, tau0_true = params[:, 1:4].T
        dist_params = np.column_stack([tau0_true, beta_true, delta_true])

        # Lifetime distributions used to generate the trajectory.
        dist = None
        with mdt.fh.xopen(args.INFILE_PARAM, "r") as file:
            for line in file.readlines():
                if line.startswith("# Lifetime dist.:"):
                    dist = line.split()[-1]
                    break
        if dist is None:
            raise ValueError(
                "Could not determine the used lifetime distribution from"
                " {}".format(args.INFILE_PARAM)
            )
        elif dist == "generalized_gamma":
            lt_dists = [
                stats.gengamma(
                    a=delta_true[i] / beta_true[i],
                    c=beta_true[i],
                    loc=0,
                    scale=tau0_true[i],
                )
                for i in range(n_states)
            ]
        elif dist == "burr12":
            lt_dists = [
                stats.burr12(
                    c=beta_true[i], d=delta_true[i], loc=0, scale=tau0_true[i]
                )
                for i in range(n_states)
            ]
        else:
            raise ValueError("Unknown lifetime distribution: {}".format(dist))

        lts_true_rp_goodness = np.full((n_states, 2), np.nan, dtype=np.float64)
        lts_true_km_goodness = np.full_like(lts_true_rp_goodness, np.nan)
        lts_true_characs = np.full(
            (n_states, 6 + n_moms), np.nan, dtype=np.float64
        )
        for i in range(n_states):
            # Quantities to assess the fit goodness if the estimated
            # survival function is seen as fit of the true survival
            # function.
            sf_true = lt_dists[i].sf(times)
            rp = remain_probs.T[i]
            valid = np.isfinite(rp)
            lts_true_rp_goodness[i] = np.array(
                fit_goodness(data=sf_true[valid], fit=rp[valid])
            )
            sf = km_surv_funcs.T[i]
            valid = np.isfinite(sf)
            lts_true_km_goodness[i] = np.array(
                fit_goodness(data=sf_true[valid], fit=sf[valid])
            )
            # Calculate distribution characteristics.
            raw_moms = [lt_dists[i].moment(n) for n in range(1, n_moms + 1)]
            var, skew, kurt = lt_dists[i].stats(moments="vsk")
            std = np.sqrt(var)
            cv = std / raw_moms[0]
            median = lt_dists[i].median()
            skew_non_param = np.divide((raw_moms[0] - median), std)
            lts_true_characs[i] = np.array(
                [
                    raw_moms[0],  # Mean.
                    std,  # Standard deviation.
                    cv,  # Coefficient of variation.
                    skew,  # Skewness (Fisher).
                    kurt,  # Excess kurtosis (Fisher).
                    median,  # Median
                    skew_non_param,  # Non-parametric skewness.
                    *raw_moms[1:],  # 2nd to `n_moms`-th raw moment.
                ]
            )
    ####################################################################

    ####################################################################
    print("\n")
    print("Creating text output...")
    timer = datetime.now()
    data = [
        states,  # 1
        # Method 1: Censored counting.
        lts_cnt_cen_characs,  # 2-15
        # Method 2: Uncensored counting.
        lts_cnt_unc_characs,  # 16-29
        # Method 3: Inverse transition rate.
        lts_k,  # 30
        # Method 4: Numerical integration of the remain probability.
        lts_rp_int_characs,  # 31-40
        # Method 5: Weibull fit of the remain probability.
        lts_rp_wbl_characs,  # 41-50
        tau0_rp_wbl,  # 51
        tau0_rp_wbl_sd,  # 52
        beta_rp_wbl,  # 53
        beta_rp_wbl_sd,  # 54
        lts_rp_wbl_fit_goodness,  # 55-56
        # Method 6: Burr Type XII fit of the remain probability.
        lts_rp_brr_characs,  # 57-66
        tau0_rp_brr,  # 67
        tau0_rp_brr_sd,  # 68
        beta_rp_brr,  # 69
        beta_rp_brr_sd,  # 70
        delta_rp_brr,  # 71
        delta_rp_brr_sd,  # 72
        lts_rp_brr_fit_goodness,  # 73-74
        # Fit region for the remain probability.
        fit_start_rp * args.TIME_CONV,  # 75
        (fit_stop_rp - 1) * args.TIME_CONV,  # 76
        # Method 7: Numerical integration of the Kaplan-Meier estimator.
        lts_km_int_characs,  # 77-86
        # Method 8: Weibull fit of the Kaplan-Meier estimator.
        lts_km_wbl_characs,  # 87-96
        tau0_km_wbl,  # 97
        tau0_km_wbl_sd,  # 98
        beta_km_wbl,  # 99
        beta_km_wbl_sd,  # 100
        lts_km_wbl_fit_goodness,  # 101-102
        # Method 9: Burr Type XII fit of the Kaplan-Meier estimator.
        lts_km_brr_characs,  # 103-112
        tau0_km_brr,  # 113
        tau0_km_brr_sd,  # 114
        beta_km_brr,  # 115
        beta_km_brr_sd,  # 116
        delta_km_brr,  # 117
        delta_km_brr_sd,  # 118
        lts_km_brr_fit_goodness,  # 119-120
        # Fit region for the Kaplan-Meier estimator.
        fit_start_km * args.TIME_CONV,  # 121
        (fit_stop_km - 1) * args.TIME_CONV,  # 122
    ]
    if args.INFILE_PARAM is not None:
        data += [
            lts_true_characs,  # 123-132
            dist_params,  # 133-135
            lts_true_rp_goodness,  # 136-137
            lts_true_km_goodness,  # 138-139
        ]
    data = np.column_stack(data)
    header = (
        "State lifetimes.\n"
        + "Average time that a given compound stays in a given state\n"
        + "calculated either directly from the discrete trajectory\n"
        + "(Method 1-3) or from the corresponding estimate of the survival\n"
        + "function (Method 4-9). \n"
        + "\n"
        + "\n"
        + "Discrete trajectory:      {:s}\n".format(args.INFILE_DTRJ)
        + "Autocorrelation function: {:s}\n".format(args.INFILE_RP)
        + "Kaplan-Meier estimator:   {:s}\n".format(args.INFILE_KM)
        + "KM estimator variance:    {:s}\n".format(args.INFILE_KM_VAR)
    )
    if args.INFILE_PARAM is not None:
        header += (
            "Parameter file:           {:s}\n".format(args.INFILE_PARAM)
            + "\n"
            + "\n"
        )
    header += (
        "Lifetimes are calculated using different methods:\n"
        + "\n"
        + "1) The average lifetime <t_cnt_cen> is calculated by counting how\n"
        + "   many frames a given compound stays in a given state including\n"
        + "   truncated states at the trajectory edges -> censored counting.\n"
        + "   Note that lifetimes calculated in this way are usually biased\n"
        + "   to lower values because of the limited length of the\n"
        + "   trajectory and because of truncation/censoring at the\n"
        + "   trajectory edges.\n"
        + "\n"
        + "2) The average lifetime <t_cnt_unc> is calculated by counting how\n"
        + "   many frames a given compound stays in a given state excluding\n"
        + "   truncated states at the trajectory edges -> uncensored\n"
        + "   counting.  Note that lifetimes calculated in this way are\n"
        + "   usually biased to lower values because of the limited length\n"
        + "   of the trajectory.  Uncensored counting might waste a\n"
        + "   significant amount of the trajectory.\n"
        + "\n"
        + "3) The average transition rate <k> is calculated as the number of\n"
        + "   transitions leading out of a given state divided by the number\n"
        + "   of frames that compounds have spent in this state.  The\n"
        + "   average lifetime <t_k> is calculated as the inverse transition\n"
        + "   rate:\n"
        + "     <t_k> = 1 / <k>\n"
        + "\n"
        + "4) The autocorrelation function (ACF) C(t) of the existence/\n"
        + "   lifetime operator is interpreted as the survival function (SF)\n"
        + "   of the underlying lifetime distribution.  Thus, the lifetime\n"
        + "   can be calculated according to the alternative expectation\n"
        + "   formula [1]:\n"
        + "     <t_int^n> = n * int_0^inf t^(n-1) C(t) dt\n"
        + "   If C(t) does not decay below the given threshold of\n"
        + "   {:.4f}, <t_acf_int^n> is set to NaN.\n".format(args.INT_THRESH)
        + "\n"
        + "5) The ACF C(t) is fitted by the SF of the Weibull distribution\n"
        + "   (stretched exponential):\n"
        + "     S_wbl(t) = exp[-(t/tau0_wbl)^beta_wbl]\n"
        + "   with tau0_wbl > 0 and beta_wbl > 0."
        + "   The average lifetime <t_acf_wbl^n> is calculated according to\n"
        + "   the alternative expectation formula [1]:\n"
        + "     <t_wbl^n> = n * int_0^inf t^(n-1) S_wbl(t) dt\n"
        + "               = tau0_wbl^n * Gamma(1 + n/beta_bwl)\n"
        + "   where Gamma(z) is the gamma function.\n"
        + "\n"
        + "6) The ACF C(t) is fitted by the SF of a Burr Type XII\n"
        + "   distribution:\n"
        + "     S_brr(t) = 1 / [1 + (t/tau0_brr)^beta_brr]^delta_brr\n"
        + "   with tau0_brr > 0, beta_brr > 0 and beta_brr*delta_brr > 1.\n"
        + "   The average lifetime <t_brr^n> is calculated according to the\n"
        + "   alternative expectation formula [1]:\n"
        + "     <t_brr^n> = n * int_0^inf t^(n-1) S_brr(t) dt\n"
        + "               = tau0_brr^n * Gamma(delta_brr - n/beta_brr) *\n"
        + "                 Gamma(1 + n/beta_brr) / Gamma(delta_brr)\n"
        + "   where Gamma(z) is the gamma function.\n"
        + "\n"
        + "7)-9) Like 4)-6) but instead of the ACF, the Kaplan-Meier\n"
        + "   estimate of the SF is used."
        + "\n"
        + "All fits are done using scipy.optimize.curve_fit with the 'Trust\n"
        + "Region Reflective' method.  The SF is always fitted until it\n"
        + "decays below the given threshold or until the given lag time is\n"
        + "reached (whatever happens earlier).\n"
        + "\n"
        + "int_thresh = {:.4f}\n".format(args.INT_THRESH)
        + "end_fit  = {}\n".format(args.ENDFIT)
        + "stop_fit = {:.4f}\n".format(args.STOPFIT)
        + "\n"
        + "Reference [1]:\n"
        + "  S. Chakraborti, F. Jardim, E. Epprecht,\n"
        + "  Higher-order moments using the survival function: The\n"
        + "  alternative expectation formula,\n"
        + "  The American Statistician, 2019, 73, 2, 191-194."
        + "\n"
        + "\n"
        + "The columns contain:\n"
        + "  1 State index (zero-based)\n"
        + "\n"
        + "Methods based on counting frames:\n"
        + "  Method 1: Censored counting\n"
        + "  2 Sample mean (1st raw moment) / frames\n"
        + "  3 Uncertainty of the sample mean (standard error) / frames\n"
        + "  4 Corrected sample standard deviation / frames\n"
        + "  5 Corrected coefficient of variation\n"
        + "  6 Unbiased sample skewness (Fisher)\n"
        + "  7 Unbiased sample excess kurtosis (Fisher)\n"
        + "  8 Sample median / frames\n"
        + "  9 Non-parametric skewness\n"
        + " 10 2nd raw moment (biased estimate) / frames^2\n"
        + " 11 3rd raw moment (biased estimate) / frames^3\n"
        + " 12 4th raw moment (biased estimate) / frames^4\n"
        + " 13 Sample minimum / frames\n"
        + " 14 Sample maximum / frames\n"
        + " 15 Number of observations/samples\n"
        + "\n"
        + "  Method 2: Uncensored counting.\n"
        + " 16-29 As Method 1\n"
        + "\n"
        + "  Method 3: Inverse transition rate\n"
        + " 30 Mean lifetime / frames\n"
        + "\n"
        + "Methods based on the ACF:\n"
        + "  Method 4: Numerical integration of the ACF\n"
        + " 31 Mean lifetime (1st raw moment) / frames\n"
        + " 32 Standard deviation / frames\n"
        + " 33 Coefficient of variation"
        + " 34 Skewness (Fisher)\n"
        + " 35 Excess kurtosis (Fisher)\n"
        + " 36 Median / frames\n"
        + " 37 Non-parametric skewness\n"
        + " 38 2nd raw moment / frames^2\n"
        + " 39 3rd raw moment / frames^3\n"
        + " 40 4th raw moment / frames^4\n"
        + "\n"
        + "  Method 5: Weibull fit of the ACF\n"
        + " 41-50 As Method 4\n"
        + " 51 Fit parameter tau0_wbl / frames\n"
        + " 52 Standard deviation of tau0_wbl / frames\n"
        + " 53 Fit parameter beta_wbl\n"
        + " 54 Standard deviation of beta_wbl\n"
        + " 55 Coefficient of determination of the fit (R^2 value)\n"
        + " 56 Root-mean-square error (RMSE) of the fit\n"
        + "\n"
        + "  Method 6: Burr Type XII fit of the ACF\n"
        + " 57-70 As Method 5\n"
        + " 71 Fit parameter delta_brr\n"
        + " 72 Standard deviation of delta_brr\n"
        + " 73 Coefficient of determination of the fit (R^2 value)\n"
        + " 74 Root-mean-square error (RMSE) of the fit\n"
        + "\n"
        + "  Fit region for all ACF fitting methods\n"
        + " 75 Start of fit region (inclusive) / frames\n"
        + " 76 End of fit region (inclusive) / frames\n"
        + "\n"
        + "Methods based on the Kaplan-Meier estimator:\n"
        + "  Method 7: Numerical integration of the Kaplan-Meier estimator\n"
        + " 77-86 As Method 4\n"
        + "\n"
        + "  Method 8: Weibull fit of the Kaplan-Meier estimator\n"
        + " 87-102 As Method 5\n"
        + "\n"
        + "  Method 9: Burr Type XII fit of the Kaplan-Meier estimator\n"
        + " 103-120 As Method 6\n"
        + "\n"
        + "  Fit region for all Kaplan-Meier estimator fitting methods\n"
        + " 121 Start of fit region (inclusive) / frames\n"
        + " 122 End of fit region (inclusive) / frames\n"
    )
    if args.INFILE_PARAM is not None:
        header += (
            "\n"
            + "  True state lifetimes\n"
            + " 123-132 As Method 4\n"
            + " 133 Scale parameter tau0 of the true distribution\n"
            + " 134 Shape parameter beta of the true distribution\n"
            + " 135 Shape parameter delta of the true distribution\n"
            + " 136 R^2 if the ACF is seen as fit of the true SF\n"
            + " 137 RMSE of the ACF to the true SF\n"
            + " 138 R^2 if the KM estimator is seen as fit of the true SF\n"
            + " 139 RMSE of the Kaplan-Meier estimator to the true SF\n"
        )
    header += "\n" + "Column number:\n"
    header += "{:>14d}".format(1)
    for i in range(2, data.shape[-1] + 1):
        header += " {:>16d}".format(i)
    outfile = args.OUTFILE + ".txt"
    mdt.fh.savetxt(outfile, data, header=header)
    print("Created {}".format(outfile))
    print("Elapsed time:         {}".format(datetime.now() - timer))
    print("Current memory usage: {:.2f} MiB".format(mdt.rti.mem_usage(proc)))
    ####################################################################

    ####################################################################
    print("\n")
    print("Creating plot(s)...")
    timer = datetime.now()

    label_true = "True"
    # label_true_cen = "True Cens."
    # label_true_unc = "True Uncen."
    label_cnt_cen = "Cens."  # Count
    label_cnt_unc = "Uncens."  # Count
    label_k = "Rate"
    label_rp_int = "ACF Num"
    label_rp_wbl = "ACF Wbl"
    label_rp_brr = "ACF Burr"
    label_km_int = "KM Num"
    label_km_wbl = "KM Wbl"
    label_km_brr = "KM Burr"

    color_true = "tab:green"
    # color_true_cen = "tab:olive"
    # color_true_unc = "darkolivegreen"
    color_cnt_cen = "tab:orange"
    color_cnt_unc = "tab:red"
    color_k = "tab:brown"
    color_rp_int = "tab:purple"
    color_rp_wbl = "tab:blue"
    color_rp_brr = "tab:cyan"
    color_km_int = "goldenrod"
    color_km_wbl = "gold"
    color_km_brr = "yellow"

    marker_true = "*"
    # marker_true_cen = "P"
    # marker_true_unc = "X"
    marker_cnt_cen = "H"
    marker_cnt_unc = "h"
    marker_k = "p"
    marker_rp_int = "^"
    marker_rp_wbl = ">"
    marker_rp_brr = "<"
    marker_km_int = "s"
    marker_km_wbl = "D"
    marker_km_brr = "d"

    ylabel_acf = "Autocorrelation Function"
    ylabel_km = "Kaplan-Meier Estimate"

    xlabel = r"State Index"
    xlim = (np.min(states) - 0.5, np.max(states) + 0.5)
    alpha = 0.75
    cmap = plt.get_cmap()
    c_vals = np.arange(n_states)
    c_norm = max(1, n_states - 1)
    c_vals_normed = c_vals / c_norm
    colors = cmap(c_vals_normed)

    outfile = args.OUTFILE + ".pdf"
    mdt.fh.backup(outfile)
    with PdfPages(outfile) as pdf:
        ################################################################
        # Plot distribution characteristics vs. state indices.
        ylabels = (
            "Average Lifetime / Frames",
            "Std. Dev. / Frames",
            "Skewness",
            "Excess Kurtosis",
            "Median / Frames",
            "Non-Parametric Skewness",
        )
        for i, ylabel in enumerate(ylabels):
            if i == 0:
                offset_i_cnt = 0
            else:
                offset_i_cnt = 1
            fig, ax = plt.subplots(clear=True)
            if args.INFILE_PARAM is not None:
                # True lifetimes distribution.
                ax.errorbar(
                    states,
                    lts_true_characs[:, i],
                    yerr=None,
                    label=label_true,
                    color=color_true,
                    marker=marker_true,
                    alpha=alpha,
                )
            # Method 1: Censored counting.
            ax.errorbar(
                states,
                lts_cnt_cen_characs[:, i + offset_i_cnt],
                yerr=lts_cnt_cen_characs[:, i + 1] if i == 0 else None,
                label=label_cnt_cen,
                color=color_cnt_cen,
                marker=marker_cnt_cen,
                alpha=alpha,
            )
            # Method 2: Uncensored counting.
            ax.errorbar(
                states,
                lts_cnt_unc_characs[:, i + offset_i_cnt],
                yerr=lts_cnt_unc_characs[:, i + 1] if i == 0 else None,
                label=label_cnt_unc,
                color=color_cnt_unc,
                marker=marker_cnt_unc,
                alpha=alpha,
            )
            if i == 0:
                # Method 3: Inverse transition rate.
                ax.errorbar(
                    states,
                    lts_k,
                    yerr=None,
                    label=label_k,
                    color=color_k,
                    marker=marker_k,
                    alpha=alpha,
                )
            # Method 4: Numerical integration of the remain probability.
            ax.errorbar(
                states,
                lts_rp_int_characs[:, i],
                yerr=None,
                label=label_rp_int,
                color=color_rp_int,
                marker=marker_rp_int,
                alpha=alpha,
            )
            # Method 5: Weibull fit of the remain probability.
            ax.errorbar(
                states,
                lts_rp_wbl_characs[:, i],
                yerr=None,
                label=label_rp_wbl,
                color=color_rp_wbl,
                marker=marker_rp_wbl,
                alpha=alpha,
            )
            # Method 6: Burr Type XII fit of the remain probability.
            ax.errorbar(
                states,
                lts_rp_brr_characs[:, i],
                yerr=None,
                label=label_rp_brr,
                color=color_rp_brr,
                marker=marker_rp_brr,
                alpha=alpha,
            )
            # Method 7: Numerical integration of the KM estimator.
            ax.errorbar(
                states,
                lts_km_int_characs[:, i],
                yerr=None,
                label=label_km_int,
                color=color_km_int,
                marker=marker_km_int,
                alpha=alpha,
            )
            # Method 8: Weibull fit of the Kaplan-Meier estimator.
            ax.errorbar(
                states,
                lts_km_wbl_characs[:, i],
                yerr=None,
                label=label_km_wbl,
                color=color_km_wbl,
                marker=marker_km_wbl,
                alpha=alpha,
            )
            # Method 9: Burr Type XII fit of the Kaplan-Meier estimator.
            ax.errorbar(
                states,
                lts_km_brr_characs[:, i],
                yerr=None,
                label=label_km_brr,
                color=color_km_brr,
                marker=marker_km_brr,
                alpha=alpha,
            )
            ax.set(xlabel=xlabel, ylabel=ylabel, xlim=xlim)
            ylim = ax.get_ylim()
            if i not in (2, 3, 5) and ylim[0] < 0:
                ax.set_ylim(0, ylim[1])
            ax.xaxis.set_major_locator(MaxNLocator(integer=True))
            ax.set_xticks([], minor=True)
            ax.legend(ncol=3, **mdtplt.LEGEND_KWARGS_XSMALL)
            pdf.savefig()
            yd_min, yd_max = get_ydata_min_max(ax)
            if len(yd_min) > 0:
                # Set y axis to log scale.
                # Round y limits to next lower and higher power of ten.
                ylim = ax.get_ylim()
                ymin = 10 ** np.floor(np.log10(np.min(yd_min)))
                ymax = 10 ** np.ceil(np.log10(np.max(yd_max)))
                ax.set_ylim(
                    ymin if np.isfinite(ymin) else None,
                    ymax if np.isfinite(ymax) else None,
                )
                ax.set_yscale("log", base=10, subs=np.arange(2, 10))
                pdf.savefig()
            plt.close()
        ################################################################

        ################################################################
        # Plot average residual lifetime.
        if args.INFILE_PARAM is not None:
            ylabel = "Avg. Res. Lifetime / Frames"
            fig, ax = plt.subplots(clear=True)
            ax.plot(
                states,
                lts_true_characs[:, 6] / (2 * lts_true_characs[:, 0]),
                label=(
                    r"$\langle t_{true}^2 \rangle /"
                    + r" 2 \langle t_{true} \rangle$"
                ),
                color=color_true,  # color_true_cen,
                marker=marker_true,  # marker_true_cen,
                alpha=alpha,
            )
            # ax.plot(
            #     states,
            #     lts_true_characs[:, 7] / (2 * lts_true_characs[:, 6]),
            #     label=(
            #         r"$\langle t_{true}^3 \rangle /"
            #         + r" 2 \langle t_{true}^2 \rangle$"
            #     ),
            #     color=color_true_unc,
            #     marker=marker_true_unc,
            #     alpha=alpha,
            # )
            # Method 4: Numerical integration of the remain probability.
            ax.plot(
                states,
                lts_rp_int_characs[:, 0],
                label=label_rp_int + r" $\langle t \rangle$",
                color=color_rp_int,
                marker=marker_rp_int,
                alpha=alpha,
            )
            # Method 5: Weibull fit of the remain probability.
            ax.plot(
                states,
                lts_rp_wbl_characs[:, 0],
                label=label_rp_wbl + r" $\langle t \rangle$",
                color=color_rp_wbl,
                marker=marker_rp_wbl,
                alpha=alpha,
            )
            # Method 6: Burr Type XII fit of the remain probability.
            ax.plot(
                states,
                lts_rp_brr_characs[:, 0],
                label=label_rp_brr + r" $\langle t \rangle$",
                color=color_rp_brr,
                marker=marker_rp_brr,
                alpha=alpha,
            )
            ax.set(xlabel=xlabel, ylabel=ylabel, xlim=xlim)
            ylim = ax.get_ylim()
            if ylim[0] < 0:
                ax.set_ylim(0, ylim[1])
            ax.xaxis.set_major_locator(MaxNLocator(integer=True))
            ax.set_xticks([], minor=True)
            ax.legend(ncol=2, **mdtplt.LEGEND_KWARGS_XSMALL)
            pdf.savefig()
            yd_min, yd_max = get_ydata_min_max(ax)
            if len(yd_min) > 0:
                # Set y axis to log scale.
                # Round y limits to next lower and higher power of ten.
                ylim = ax.get_ylim()
                ymin = 10 ** np.floor(np.log10(np.min(yd_min)))
                ymax = 10 ** np.ceil(np.log10(np.max(yd_max)))
                ax.set_ylim(
                    ymin if np.isfinite(ymin) else None,
                    ymax if np.isfinite(ymax) else None,
                )
                ax.set_yscale("log", base=10, subs=np.arange(2, 10))
                pdf.savefig()
            plt.close()
        ################################################################

        ################################################################
        # Plot min, max and number of samples for count methods.
        ylabels = (
            "Min. Lifetime / Frames",
            "Max. Lifetime / Frames",
            "No. of Samples",
        )
        for i, ylabel in enumerate(ylabels):
            fig, ax = plt.subplots(clear=True)
            # Method 1: Censored counting.
            ax.plot(
                states,
                lts_cnt_cen_characs[:, 10 + i],
                label=label_cnt_cen,
                color=color_cnt_cen,
                marker=marker_cnt_cen,
                alpha=alpha,
            )
            # Method 2: Uncensored counting.
            ax.plot(
                states,
                lts_cnt_unc_characs[:, 10 + i],
                label=label_cnt_unc,
                color=color_cnt_unc,
                marker=marker_cnt_unc,
                alpha=alpha,
            )
            ax.set(xlabel=xlabel, ylabel=ylabel, xlim=xlim)
            ylim = ax.get_ylim()
            if ylim[0] < 0:
                ax.set_ylim(0, ylim[1])
            ax.xaxis.set_major_locator(MaxNLocator(integer=True))
            ax.set_xticks([], minor=True)
            ax.legend(**mdtplt.LEGEND_KWARGS_XSMALL)
            pdf.savefig()
            yd_min, yd_max = get_ydata_min_max(ax)
            if len(yd_min) > 0:
                # Set y axis to log scale.
                # Round y limits to next lower and higher power of ten.
                ylim = ax.get_ylim()
                ymin = 10 ** np.floor(np.log10(np.min(yd_min)))
                ymax = 10 ** np.ceil(np.log10(np.max(yd_max)))
                ax.set_ylim(
                    ymin if np.isfinite(ymin) else None,
                    ymax if np.isfinite(ymax) else None,
                )
                ax.set_yscale("log", base=10, subs=np.arange(2, 10))
                pdf.savefig()
            plt.close()
        ################################################################

        ################################################################
        # Plot fit parameters tau0, beta and delta.
        ylabels = (
            r"Fit Parameter $\tau_0$ / Frames",
            r"Fit Parameter $\beta$",
            r"Fit Parameter $\delta$",
        )
        for i, ylabel in enumerate(ylabels):
            fig, ax = plt.subplots(clear=True)
            if args.INFILE_PARAM is not None:
                # True distribution.
                ax.errorbar(
                    states,
                    dist_params[:, i],
                    yerr=None,
                    label=label_true,
                    color=color_true,
                    marker=marker_true,
                    alpha=alpha,
                )
            if i < 2:
                # Method 5: Weibull fit of the remain probability.
                ax.errorbar(
                    states,
                    popt_rp_wbl[:, i],
                    yerr=perr_rp_wbl[:, i],
                    label=label_rp_wbl,
                    color=color_rp_wbl,
                    marker=marker_rp_wbl,
                    alpha=alpha,
                )
            # Method 6: Burr Type XII fit of the remain probability.
            ax.errorbar(
                states,
                popt_conv_rp_brr[:, i],
                yerr=perr_conv_rp_brr[:, i],
                label=label_rp_brr,
                color=color_rp_brr,
                marker=marker_rp_brr,
                alpha=alpha,
            )
            if i < 2:
                # Method 8: Weibull fit of the Kaplan-Meier estimator.
                ax.errorbar(
                    states,
                    popt_km_wbl[:, i],
                    yerr=perr_km_wbl[:, i],
                    label=label_km_wbl,
                    color=color_km_wbl,
                    marker=marker_km_wbl,
                    alpha=alpha,
                )
            # Method 9: Burr Type XII fit of the Kaplan-Meier estimator.
            ax.errorbar(
                states,
                popt_conv_km_brr[:, i],
                yerr=perr_conv_km_brr[:, i],
                label=label_km_brr,
                color=color_km_brr,
                marker=marker_km_brr,
                alpha=alpha,
            )
            ax.set(xlabel=xlabel, ylabel=ylabel, xlim=xlim)
            ylim = ax.get_ylim()
            if ylim[0] < 0:
                ax.set_ylim(0, ylim[1])
            ax.xaxis.set_major_locator(MaxNLocator(integer=True))
            ax.set_xticks([], minor=True)
            ax.legend(ncol=2, **mdtplt.LEGEND_KWARGS_XSMALL)
            pdf.savefig()
            yd_min, yd_max = get_ydata_min_max(ax)
            if len(yd_min) > 0:
                # Set y axis to log scale.
                # Round y limits to next lower and higher power of ten.
                ylim = ax.get_ylim()
                ymin = 10 ** np.floor(np.log10(np.min(yd_min)))
                ymax = 10 ** np.ceil(np.log10(np.max(yd_max)))
                ax.set_ylim(
                    ymin if np.isfinite(ymin) else None,
                    ymax if np.isfinite(ymax) else None,
                )
                ax.set_yscale("log", base=10, subs=np.arange(2, 10))
                pdf.savefig()
            plt.close()
        ################################################################

        ################################################################
        # Plot goodness of fit quantities.
        ylabels = (r"Coeff. of Determ. $R^2$", "RMSE")
        for i, ylabel in enumerate(ylabels):
            fig, ax = plt.subplots(clear=True)
            if args.INFILE_PARAM is not None:
                # Remain probability to the true survival function.
                ax.plot(
                    states,
                    lts_true_rp_goodness[:, i],
                    label="ACF to True",
                    color=color_rp_int,
                    marker=marker_rp_int,
                    alpha=alpha,
                )
            # Method 5: Weibull fit of the remain probability.
            ax.plot(
                states,
                lts_rp_wbl_fit_goodness[:, i],
                label=label_rp_wbl,
                color=color_rp_wbl,
                marker=marker_rp_wbl,
                alpha=alpha,
            )
            # Method 6: Burr Type XII fit of the remain probability.
            ax.plot(
                states,
                lts_rp_brr_fit_goodness[:, i],
                label=label_rp_brr,
                color=color_rp_brr,
                marker=marker_rp_brr,
                alpha=alpha,
            )
            if args.INFILE_PARAM is not None:
                # Kaplan-Meier estimator to the true survival function.
                ax.plot(
                    states,
                    lts_true_km_goodness[:, i],
                    label="KM to True",
                    color=color_km_int,
                    marker=marker_km_int,
                    alpha=alpha,
                )
            # Method 8: Weibull fit of the Kaplan-Meier estimator.
            ax.plot(
                states,
                lts_km_wbl_fit_goodness[:, i],
                label=label_km_wbl,
                color=color_km_wbl,
                marker=marker_km_wbl,
                alpha=alpha,
            )
            # Method 9: Burr Type XII fit of the Kaplan-Meier estimator.
            ax.plot(
                states,
                lts_km_brr_fit_goodness[:, i],
                label=label_km_brr,
                color=color_km_brr,
                marker=marker_km_brr,
                alpha=alpha,
            )
            ax.set(xlabel=xlabel, ylabel=ylabel, xlim=xlim)
            ylim = ax.get_ylim()
            if ylim[0] < 0:
                ax.set_ylim(0, ylim[1])
            ax.xaxis.set_major_locator(MaxNLocator(integer=True))
            ax.set_xticks([], minor=True)
            ax.legend(ncol=2, **mdtplt.LEGEND_KWARGS_XSMALL)
            pdf.savefig()
            yd_min, yd_max = get_ydata_min_max(ax)
            if len(yd_min) > 0:
                # Set y axis to log scale.
                # Round `ymin` to next lower power of ten.
                ylim = ax.get_ylim()
                ymin = 10 ** np.floor(np.log10(np.min(yd_min)))
                if i == 0:
                    ymax = 2
                else:
                    ymax = 10 ** np.ceil(np.log10(np.max(yd_max)))
                ax.set_ylim(
                    ymin if np.isfinite(ymin) else None,
                    ymax if np.isfinite(ymax) else None,
                )
                ax.set_yscale("log", base=10, subs=np.arange(2, 10))
                pdf.savefig()
            plt.close()
        ################################################################

        ################################################################
        # Plot end of fit region.
        ylabel = "End of Fit Region / Frames"
        fig, ax = plt.subplots(clear=True)
        # Fit of remain probability.
        ax.plot(
            states,
            (fit_stop_rp - 1) * args.TIME_CONV,
            label="ACF",
            color=color_rp_wbl,
            marker=marker_rp_wbl,
        )
        # Fit of Kaplan-Meier estimator.
        ax.plot(
            states,
            (fit_stop_km - 1) * args.TIME_CONV,
            label="KM",
            color=color_km_wbl,
            marker=marker_km_wbl,
        )
        ax.set(xlabel=xlabel, ylabel=ylabel, xlim=xlim)
        ylim = ax.get_ylim()
        if ylim[0] < 0:
            ax.set_ylim(0, ylim[1])
        ax.xaxis.set_major_locator(MaxNLocator(integer=True))
        ax.set_xticks([], minor=True)
        ax.legend(**mdtplt.LEGEND_KWARGS_XSMALL)
        pdf.savefig()
        # Set y axis to log scale.
        ax.set_yscale("log", base=10, subs=np.arange(2, 10))
        pdf.savefig()
        plt.close()
        ################################################################

        if args.INFILE_PARAM is not None:
            ############################################################
            # Plot remain probabilities and true survival functions for
            # each state.
            fig, ax = plt.subplots(clear=True)
            ax.set_prop_cycle(color=colors)
            for i, rp in enumerate(remain_probs.T):
                lines = ax.plot(
                    times,
                    rp,
                    label=r"$%d$" % states[i],
                    linewidth=1,
                    alpha=alpha,
                )
                ax.plot(
                    times,
                    lt_dists[i].sf(times),
                    label=r"$S_{true}(t)$" if i == n_states - 1 else None,
                    linestyle="dashed",
                    color=lines[0].get_color(),
                    alpha=alpha,
                )
            ax.set(
                xlabel="Time / Frames",
                ylabel=ylabel_acf,
                xlim=(times[1], times[-1]),
                ylim=(0, 1),
            )
            ax.set_xscale("log", base=10, subs=np.arange(2, 10))
            legend = ax.legend(
                title="State Index",
                loc="upper right",
                ncol=2,
                **mdtplt.LEGEND_KWARGS_XSMALL,
            )
            legend.get_title().set_multialignment("center")
            pdf.savefig()
            plt.close()

            # Plot difference of the remain probabilities to the true
            # survival functions for each state.
            fig, ax = plt.subplots(clear=True)
            ax.set_prop_cycle(color=colors)
            for i, rp in enumerate(remain_probs.T):
                res = lt_dists[i].sf(times) - rp
                ax.plot(times, res, label=r"$%d$" % states[i], alpha=alpha)
            ax.set(
                xlabel="Time / Frames",
                ylabel=r"$S_{true}(t) - C(t)$",
                xlim=(times[1], times[-1]),
            )
            ax.set_xscale("log", base=10, subs=np.arange(2, 10))
            legend = ax.legend(
                title="State Index",
                loc="lower right",
                ncol=2,
                **mdtplt.LEGEND_KWARGS_XSMALL,
            )
            legend.get_title().set_multialignment("center")
            pdf.savefig()
            plt.close()
            ############################################################

            ############################################################
            # Plot Kaplan-Meier estimates and true survival functions
            # for each state.
            fig, ax = plt.subplots(clear=True)
            ax.set_prop_cycle(color=colors)
            for i, km in enumerate(km_surv_funcs.T):
                lines = ax.plot(
                    times,
                    km,
                    label=r"$%d$" % states[i],
                    linewidth=1,
                    alpha=alpha,
                )
                ax.plot(
                    times,
                    lt_dists[i].sf(times),
                    label=r"$S_{true}(t)$" if i == n_states - 1 else None,
                    linestyle="dashed",
                    color=lines[0].get_color(),
                    alpha=alpha,
                )
            ax.set(
                xlabel="Time / Frames",
                ylabel=ylabel_km,
                xlim=(times[1], times[-1]),
                ylim=(0, 1),
            )
            ax.set_xscale("log", base=10, subs=np.arange(2, 10))
            legend = ax.legend(
                title="State Index",
                loc="upper right",
                ncol=2,
                **mdtplt.LEGEND_KWARGS_XSMALL,
            )
            legend.get_title().set_multialignment("center")
            pdf.savefig()
            plt.close()

            # Plot difference of the Kaplan-Meier estimates to the true
            # survival functions for each state.
            fig, ax = plt.subplots(clear=True)
            ax.set_prop_cycle(color=colors)
            for i, km in enumerate(km_surv_funcs.T):
                res = lt_dists[i].sf(times) - km
                ax.plot(times, res, label=r"$%d$" % states[i], alpha=alpha)
            ax.set(
                xlabel="Time / Frames",
                ylabel=r"$S_{true}(t) - S_{KM}(t)$",
                xlim=(times[1], times[-1]),
            )
            ax.set_xscale("log", base=10, subs=np.arange(2, 10))
            legend = ax.legend(
                title="State Index",
                loc="lower right",
                ncol=2,
                **mdtplt.LEGEND_KWARGS_XSMALL,
            )
            legend.get_title().set_multialignment("center")
            pdf.savefig()
            plt.close()
            ############################################################

        ################################################################
        # Plot remain probabilities and Weibull fits for each state.
        fig, ax = plt.subplots(clear=True)
        ax.set_prop_cycle(color=colors)
        for i, rp in enumerate(remain_probs.T):
            times_fit = times[fit_start_rp[i] : fit_stop_rp[i]]
            fit = mdt.func.kww(times_fit, *popt_rp_wbl[i])
            lines = ax.plot(
                times, rp, label=r"$%d$" % states[i], linewidth=1, alpha=alpha
            )
            ax.plot(
                times_fit,
                fit,
                label="Wbl Fit" if i == n_states - 1 else None,
                linestyle="dashed",
                color=lines[0].get_color(),
                alpha=alpha,
            )
        ax.set(
            xlabel="Time / Frames",
            ylabel=ylabel_acf,
            xlim=(times[1], times[-1]),
            ylim=(0, 1),
        )
        ax.set_xscale("log", base=10, subs=np.arange(2, 10))
        legend = ax.legend(
            title="State Index",
            loc="upper right",
            ncol=2,
            **mdtplt.LEGEND_KWARGS_XSMALL,
        )
        legend.get_title().set_multialignment("center")
        pdf.savefig()
        plt.close()

        # Plot Weibull fit residuals (remain probability) for each state
        fig, ax = plt.subplots(clear=True)
        ax.set_prop_cycle(color=colors)
        for i, rp in enumerate(remain_probs.T):
            times_fit = times[fit_start_rp[i] : fit_stop_rp[i]]
            fit = mdt.func.kww(times_fit, *popt_rp_wbl[i])
            res = rp[fit_start_rp[i] : fit_stop_rp[i]] - fit
            ax.plot(times_fit, res, label=r"$%d$" % states[i], alpha=alpha)
        ax.set(
            xlabel="Time / Frames",
            ylabel="ACF Weibull Fit Res.",
            xlim=(times[1], times[-1]),
        )
        ax.set_xscale("log", base=10, subs=np.arange(2, 10))
        legend = ax.legend(
            title="State Index",
            loc="lower right",
            ncol=2,
            **mdtplt.LEGEND_KWARGS_XSMALL,
        )
        legend.get_title().set_multialignment("center")
        pdf.savefig()
        plt.close()
        ################################################################

        ################################################################
        # Plot Kaplan-Meier estimates and Weibull fits for each state.
        fig, ax = plt.subplots(clear=True)
        ax.set_prop_cycle(color=colors)
        for i, km in enumerate(km_surv_funcs.T):
            times_fit = times[fit_start_km[i] : fit_stop_km[i]]
            fit = mdt.func.kww(times_fit, *popt_km_wbl[i])
            lines = ax.plot(
                times, km, label=r"$%d$" % states[i], linewidth=1, alpha=alpha
            )
            ax.plot(
                times_fit,
                fit,
                label="Wbl Fit" if i == n_states - 1 else None,
                linestyle="dashed",
                color=lines[0].get_color(),
                alpha=alpha,
            )
        ax.set(
            xlabel="Time / Frames",
            ylabel=ylabel_km,
            xlim=(times[1], times[-1]),
            ylim=(0, 1),
        )
        ax.set_xscale("log", base=10, subs=np.arange(2, 10))
        legend = ax.legend(
            title="State Index",
            loc="upper right",
            ncol=2,
            **mdtplt.LEGEND_KWARGS_XSMALL,
        )
        legend.get_title().set_multialignment("center")
        pdf.savefig()
        plt.close()

        # Plot Weibull fit residuals (Kaplan-Meier) for each state.
        fig, ax = plt.subplots(clear=True)
        ax.set_prop_cycle(color=colors)
        for i, km in enumerate(km_surv_funcs.T):
            times_fit = times[fit_start_km[i] : fit_stop_km[i]]
            fit = mdt.func.kww(times_fit, *popt_km_wbl[i])
            res = km[fit_start_km[i] : fit_stop_km[i]] - fit
            ax.plot(times_fit, res, label=r"$%d$" % states[i], alpha=alpha)
        ax.set(
            xlabel="Time / Frames",
            ylabel="KM Weibull Fit Res.",
            xlim=(times[1], times[-1]),
        )
        ax.set_xscale("log", base=10, subs=np.arange(2, 10))
        legend = ax.legend(
            title="State Index",
            loc="lower right",
            ncol=2,
            **mdtplt.LEGEND_KWARGS_XSMALL,
        )
        legend.get_title().set_multialignment("center")
        pdf.savefig()
        plt.close()
        ################################################################

        ################################################################
        # Plot remain probabilities and Burr fits for each state.
        fig, ax = plt.subplots(clear=True)
        ax.set_prop_cycle(color=colors)
        for i, rp in enumerate(remain_probs.T):
            times_fit = times[fit_start_rp[i] : fit_stop_rp[i]]
            fit = mdt.func.burr12_sf_alt(times_fit, *popt_rp_brr[i])
            lines = ax.plot(
                times, rp, label=r"$%d$" % states[i], linewidth=1, alpha=alpha
            )
            ax.plot(
                times_fit,
                fit,
                label="Burr Fit" if i == n_states - 1 else None,
                linestyle="dashed",
                color=lines[0].get_color(),
                alpha=alpha,
            )
        ax.set(
            xlabel="Time / Frames",
            ylabel=ylabel_acf,
            xlim=(times[1], times[-1]),
            ylim=(0, 1),
        )
        ax.set_xscale("log", base=10, subs=np.arange(2, 10))
        legend = ax.legend(
            title="State Index",
            loc="upper right",
            ncol=2,
            **mdtplt.LEGEND_KWARGS_XSMALL,
        )
        legend.get_title().set_multialignment("center")
        pdf.savefig()
        plt.close()

        # Plot Burr fit residuals (remain probability) for each state.
        fig, ax = plt.subplots(clear=True)
        ax.set_prop_cycle(color=colors)
        for i, rp in enumerate(remain_probs.T):
            times_fit = times[fit_start_rp[i] : fit_stop_rp[i]]
            fit = mdt.func.burr12_sf_alt(times_fit, *popt_rp_brr[i])
            res = rp[fit_start_rp[i] : fit_stop_rp[i]] - fit
            ax.plot(times_fit, res, label=r"$%d$" % states[i], alpha=alpha)
        ax.set(
            xlabel="Time / Frames",
            ylabel="ACF Burr Fit Res.",
            xlim=(times[1], times[-1]),
        )
        ax.set_xscale("log", base=10, subs=np.arange(2, 10))
        legend = ax.legend(
            title="State Index",
            loc="lower right",
            ncol=2,
            **mdtplt.LEGEND_KWARGS_XSMALL,
        )
        legend.get_title().set_multialignment("center")
        pdf.savefig()
        plt.close()
        ################################################################

        ################################################################
        # Plot Kaplan-Meier estimates and Burr fits for each state.
        fig, ax = plt.subplots(clear=True)
        ax.set_prop_cycle(color=colors)
        for i, km in enumerate(km_surv_funcs.T):
            times_fit = times[fit_start_km[i] : fit_stop_km[i]]
            fit = mdt.func.burr12_sf_alt(times_fit, *popt_km_brr[i])
            lines = ax.plot(
                times, km, label=r"$%d$" % states[i], linewidth=1, alpha=alpha
            )
            ax.plot(
                times_fit,
                fit,
                label="Burr Fit" if i == n_states - 1 else None,
                linestyle="dashed",
                color=lines[0].get_color(),
                alpha=alpha,
            )
        ax.set(
            xlabel="Time / Frames",
            ylabel=ylabel_km,
            xlim=(times[1], times[-1]),
            ylim=(0, 1),
        )
        ax.set_xscale("log", base=10, subs=np.arange(2, 10))
        legend = ax.legend(
            title="State Index",
            loc="upper right",
            ncol=2,
            **mdtplt.LEGEND_KWARGS_XSMALL,
        )
        legend.get_title().set_multialignment("center")
        pdf.savefig()
        plt.close()

        # Plot Burr fit residuals (Kaplan-Meier) for each state.
        fig, ax = plt.subplots(clear=True)
        ax.set_prop_cycle(color=colors)
        for i, km in enumerate(km_surv_funcs.T):
            times_fit = times[fit_start_km[i] : fit_stop_km[i]]
            fit = mdt.func.burr12_sf_alt(times_fit, *popt_km_brr[i])
            res = km[fit_start_km[i] : fit_stop_km[i]] - fit
            ax.plot(times_fit, res, label=r"$%d$" % states[i], alpha=alpha)
        ax.set(
            xlabel="Time / Frames",
            ylabel="KM Burr Fit Res.",
            xlim=(times[1], times[-1]),
        )
        ax.set_xscale("log", base=10, subs=np.arange(2, 10))
        legend = ax.legend(
            title="State Index",
            loc="lower right",
            ncol=2,
            **mdtplt.LEGEND_KWARGS_XSMALL,
        )
        legend.get_title().set_multialignment("center")
        pdf.savefig()
        plt.close()
        ################################################################
    print("Created {}".format(outfile))
    print("Elapsed time:         {}".format(datetime.now() - timer))
    print("Current memory usage: {:.2f} MiB".format(mdt.rti.mem_usage(proc)))
    ####################################################################

    print("\n")
    print("{} done".format(os.path.basename(sys.argv[0])))
    print("Totally elapsed time: {}".format(datetime.now() - timer_tot))
    _cpu_time = timedelta(seconds=sum(proc.cpu_times()[:4]))
    print("CPU time:             {}".format(_cpu_time))
    print("CPU usage:            {:.2f} %".format(proc.cpu_percent()))
    print("Current memory usage: {:.2f} MiB".format(mdt.rti.mem_usage(proc)))
