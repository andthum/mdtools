#!/usr/bin/env python3

# This file is part of MDTools.
# Copyright (C) 2021-2023  The MDTools Development Team and all
# contributors listed in the file AUTHORS.rst
#
# MDTools is free software: you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation, either version 3 of the License, or (at your
# option) any later version.
#
# MDTools is distributed in the hope that it will be useful, but WITHOUT
# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
# for more details.
#
# You should have received a copy of the GNU General Public License
# along with MDTools.  If not, see <http://www.gnu.org/licenses/>.


r"""
Compare state lifetimes calculated from a discrete trajectory using
different methods.

.. note::

    The term "remain probability" refers to the intermittent or
    continuous autocorrelation function of the existence/lifetime
    operator.  These autocorrelation functions are frequently used in
    the molecular dynamics literature as estimates for the survival
    function of hydrogen (and other) bonds.

Options
-------
--dtrj
    Name of the file containing the discrete trajectory.  The discrete
    trajectory must be stored as :class:`numpy.ndarray` either in a
    binary NumPy |npy_file| or in a (compressed) NumPy |npz_archive|.
    See :func:`mdtools.file_handler.load_dtrj` for more information
    about the requirements for the input file.
--rp
    Name of the file containing the remain probabilities for each state
    as generated by
    :mod:`scripts.discretization.state_lifetime_discrete`.
--km
    Name of the file containing the Kaplan-Meier estimate of the
    survival function as generated by
    :mod:`scripts.discretization.kaplan_meier_discrete`.
--param
    File containing the parameters that were used to generate the
    artificial discrete trajectory as created by
    :mod:`misc.dtrj_lifetimes.generate_dtrj.py` (optional).  If
    provided, the true lifetimes are also plotted.
-o
    Output filename pattern.
--int-thresh
    Only calculate the lifetime by directly integrating the estimated
    survival function if the survival function decays below the given
    threshold.  Default: ``0.01``.
--end-fit
    End time for fitting the estimated survival function (in trajectory
    steps).  This is inclusive, i.e. the time given here is still
    included in the fit.  If ``None``, the fit ends at 90% of the lag
    times.  Default: ``None``.
--stop-fit
    Stop fitting the estimated survival function as soon as it falls
    below the given value.  The fitting is stopped by whatever happens
    earlier: \--end-fit or \--stop-fit.  Default: ``0.01``.
--time-conv
    Time conversion factor.  Multiply times by this factor.  Default:
    ``1``.

See Also
--------
:mod:`misc.dtrj_lifetimes.generate_dtrj` :
    Generate an artificial discrete trajectory with a given number of
    states with a given lifetime distribution

Notes
-----
.. code-block:: bash

    for dtrj in *.npz; do
        fname="${dtrj::-4}"
        python3 compare_dtrj_lifetime_methods.py \
            --dtrj "${dtrj}" \
            --rp "${fname}_state_lifetime_discrete_continuous.txt.gz" \
            --param "${fname}_param.txt.gz" \
            -o "${fname}_compare_dtrj_lifetime_methods"
    done

"""


__author__ = "Andreas Thum"


# Standard libraries
import argparse
import os
import sys
import warnings
from datetime import datetime, timedelta

# Third-party libraries
import matplotlib.pyplot as plt
import numpy as np
import psutil
from matplotlib.backends.backend_pdf import PdfPages
from matplotlib.ticker import MaxNLocator
from scipy import stats

# First-party libraries
import mdtools as mdt
import mdtools.plot as mdtplt  # Load MDTools plot style  # noqa: F401


def read_sf_from_file(
    fname, fname_var=None, time_conv=1, n_frames_check=None, states_check=None
):
    """
    Read the survival function for each state from file.

    Parameters
    ----------
    fname : str or bytes or os.PathLike
        Name of the file containing the survival function for each
        state.  The file must contain a data matrix where the first row
        contains the state indices, the first column contains the lag
        times and the remaining matrix elements contain the
        corresponding values of the survival function.  Such files are
        e.g. generated by
        :mod:`scripts.discretization.state_lifetime_discrete` or
        :mod:`scripts.discretization.kaplan_meier_discrete`.
    fname_var : str or bytes or os.PathLike or None, optional
        Optional name of the file containing the variance of the
        survival function.  The file must have the same format as the
        first one.
    time_conv : scalar, optional
        Time conversion factor.  All lag times read from the input file
        are multiplied by this factor.
    n_frames_check : int or None, optional
        Number of expected frames.  If provided, the lag times (in
        trajectory steps) that were read from the input file will be
        checked against the lag times that are to be expected from the
        given number of frames.
    states_check : array_like or None, optional
        Expected state indices.  If provided, the state indices that
        were read from the input file are checked against the provided
        state indices.

    Returns
    -------
    surv_funcs : numpy.ndarray
        Array of shape ``(t, s)`` where ``t`` is the number of lag times
        and ``s`` is the number of different states.  The ij-th element
        of `surv_funcs` is the value of the survival function of state
        j after a lag time of i frames.
    surv_funcs_var : numpy.ndarray
        Array of the same shape as `surv_funcs` containing the variance
        of the survival function.  Only returned if `fname_var` was
        provided.
    times : numpy.ndarray
        Array of shape ``(t,)`` containing the corresponding lag times.
    states : numpy.ndarray
        Array of shape ``(s,)`` containing the corresponding state
        indices.

    Raises
    ------
    ValueError :
        If a value of `surv_funcs` lies outside the interval [0, 1]; or
        if the lag times that were read from the input file are not
        equal to the expected lag times; or
        if the state indices that were read from the input file are not
        equal to the given state indices.
    """
    surv_funcs = np.loadtxt(fname)
    states = surv_funcs[0, 1:]  # State indices.
    times = surv_funcs[1:, 0]  # Lag times in trajectory steps.
    surv_funcs = surv_funcs[1:, 1:]  # Survival functions for each state
    if np.any(surv_funcs < 0) or np.any(surv_funcs > 1):
        raise ValueError(
            "Some survival function values lie outside the interval [0, 1]."
            "  Input file: {}".format(fname)
        )
    if n_frames_check is not None and not np.array_equal(
        times, np.arange(n_frames_check)
    ):
        raise ValueError(
            "`times` != `np.arange(n_frames_check)`.  Input file:"
            " {}".format(n_frames_check)
        )
    times *= time_conv  # Converted lag times.
    if np.any(np.modf(states)[0] != 0):
        raise ValueError(
            "Some state indices are not integers but floats.  `states` ="
            " {}.  Input file: {}".format(states, fname)
        )
    states = states.astype(np.int64)
    if states_check is not None and not np.array_equal(states, states_check):
        raise ValueError(
            "`states` ({}) != `states_check` ({}).  Input file:"
            " {}".format(states, states_check, fname)
        )

    if fname_var is not None:
        surv_funcs_var, times_var, states_var = read_sf_from_file(
            fname=fname_var,
            fname_var=None,
            time_conv=time_conv,
            n_frames_check=n_frames_check,
            states_check=states_check,
        )
        if surv_funcs_var.shape != surv_funcs.shape:
            raise ValueError(
                "`surv_funcs_var.shape` ({}) != `surv_funcs.shape` ({})."
                "  Input file: ({})".format(
                    surv_funcs_var.shape, surv_funcs.shape, fname_var
                )
            )
        if not np.allclose(times_var, times, rtol=0):
            raise ValueError(
                "`times_var` != `times`.  Input file: {}".format(fname_var)
            )
        if not np.array_equal(states_var, states, rtol=0):
            raise ValueError(
                "`states_var` != `states`.  Input file: {}".format(fname_var)
            )
        return surv_funcs, surv_funcs_var, times, states
    else:
        return surv_funcs, times, states


def dist_characs(a, axis=-1, n_moms=4):
    """
    Estimate distribution characteristics from a given sample.

    Parameters
    ----------
    a : array_like
        Array of samples.
    axis : int, optional
        The axis along which to compute the distribution
        characteristics.
    n_moms : int, optional
        Number of raw moments to calculate.

    Returns
    -------
    characs : numpy.ndarray
        Array of shape ``(9 + n_moms-1, )`` containing the following
        distribution characteristics:

            1. Sample mean (unbiased 1st raw moment)
            2. Uncertainty of the sample mean (standard error)
            3. 2nd raw moment (biased estimate)
            4. 3rd raw moment (biased estimate)
            5. 4th raw moment (biased estimate)
            6. Corrected sample standard deviation
            7. Unbiased sample skewness
            8. Unbiased sample excess kurtosis (according to Fisher)
            9. Sample median
            10. Sample minimum
            11. Sample maximum
            12. Number of samples

        The number of calculated raw moments depends on `n_moms`.  The
        first raw moment (mean) is always calculated.
    """
    a = np.asarray(a)
    nobs, min_max, mean, var, skew, kurt = stats.describe(
        a, axis=axis, ddof=1, bias=False
    )
    median = np.median(a, axis=axis)
    raw_moments = [np.mean(a**n) for n in range(2, n_moms + 1)]
    characs = np.array(
        [
            mean,  # Sample mean.
            np.sqrt(np.divide(var, nobs)),  # Uncertainty of sample mean
            *raw_moments,  # 2nd to 4th raw moment.
            np.sqrt(var),  # Corrected sample standard deviation.
            skew,  # Unbiased sample skewness.
            kurt,  # Unbiased sample excess kurtosis (Fisher).
            median,  # Median of the sample.
            min_max[0],  # Minimum value of the sample.
            min_max[1],  # Maximum value of the sample.
            nobs,  # Number of observations (sample points).
        ]
    )
    return characs


def count_method(dtrj, uncensored=False, time_conv=1, states=None):
    """
    Estimate characteristics of the underlying lifetime distribution
    from a sample of lifetimes.

    Take a discrete trajectory and count the number of frames that a
    given compound stays in a given state.  Estimate characteristics of
    the underlying lifetime distribution from the obtained sample.

    Parameters
    ----------
    dtrj : array_like
        The discrete trajectory.  Array of shape ``(n, f)``, where ``n``
        is the number of compounds and ``f`` is the number of frames.
        The shape can also be ``(f,)``, in which case the array is
        expanded to shape ``(1, f)``.   The elements of `dtrj` are
        interpreted as the indices of the states in which a given
        compound is at a given frame.
    uncensored : bool, optional
        If ``True`` only take into account uncensored states, i.e.
        states whose start and end lie within the trajectory.  In other
        words, discard the truncated (censored) states at the beginning
        and end of the trajectory.  For these states the start/end time
        is unknown.
    time_conv : scalar, optional
        Time conversion factor.  All lifetimes are multiplied by this
        factor.
    states : array_like or None, optional
        Expected state indices.  If provided, the state indices in the
        discrete trajectory are checked against the provided state
        indices.

    Returns
    -------
    characs : numpy.ndarray
        Estimated distribution characteristics.  See
        :func:`dist_characs` for more details.
    states : numpy.ndarray
        The state indices.

    Raises
    ------
    ValueError :
        If the state indices in the given discrete trajectory are not
        contained in the given array of state indices.
    """
    lts_per_state, states_dtrj = mdt.dtrj.lifetimes_per_state(
        dtrj, uncensored=uncensored, return_states=True
    )
    lts_per_state = [lts * time_conv for lts in lts_per_state]
    if states is not None and not np.all(np.isin(states_dtrj, states)):
        raise ValueError(
            "`states_dtrj` ({}) is not fully contained in `states`"
            " ({})".format(states_dtrj, states)
        )
    characs = np.full((len(states), 12), np.nan, dtype=np.float64)
    characs[:, -1] = 0  # Default number of observations.
    for i, lts in enumerate(lts_per_state):
        if len(lts) == 0:
            if not uncensored:
                raise ValueError(
                    "`len(lts) == 0` although `uncensored` is False"
                )
            continue
        else:
            characs[i] = dist_characs(lts)
    return characs, states


def cross(y, x, f):
    r"""
    Return the `x` value where the array `f` falls below the given `y`
    value for the first time.

    If `f` never falls below the given `y` value, ``numpy.nan`` is
    returned.

    If `f` falls immediately below the given `y` value, ``0`` is
    returned.

    Parameters
    ----------
    y : scalar
        The `y` value for which to get the `x` value.
    x, f : array_like
        The `x` values and corresponding `f` values.

    Returns
    -------
    x_of_y : scalar
        The `x` value that belongs to the given `y` value.
    """
    ix_y = np.nanargmax(f <= y)
    if f[ix_y] > y:
        # `f` never falls below the given `y` value.
        return np.nan
    elif ix_y < 1:
        # `f` falls immediately below the given `y` value.
        return 0
    elif f[ix_y] == y:
        return x[ix_y]
    else:
        # Linearly interpolate between `f[ix_y]` and `f[ix_y - 1]` to
        # estimate the `x` value that belongs to the given `y` value.
        slope = f[ix_y] - f[ix_y - 1]
        slope /= x[ix_y] - x[ix_y - 1]
        intercept = f[ix_y] - slope * x[ix_y]
        return (y - intercept) / slope


def raw_moment_integrate(sf, x, n=1):
    r"""
    Calculate the :math:`n`-th raw moment through numerical integration
    of the survival function using the alternative expectation formula.
    [1]_

    .. math::

        \langle x^n \rangle =
        n \int_{-\infty}^\infty x^{n-1} S(x) \text{ d}x

    Here, :math:`S(x)` is the survival function of the probability
    density function of :math:`x`.  The integral is evaluated
    numerically using :func:`numpy.trapz`.

    Parameters
    ----------
    sf : array_like
        Values of the survival function :math:`S(x)`.
    x : array_like
        Corresponding :math:`x` values.
    n : int, optional
        Order of the moment.

    Returns
    -------
    rm_n : float
        The :math:`n`-th raw moment.

    Notes
    -----
    Values where `sf` or `x` are NaN or infinite are removed prior to
    computing the integral.

    References
    ----------
    .. [1] S. Chakraborti, F. Jardim, E. Epprecht,
        `Higher-order moments using the survival function: The
        alternative expectation formula
        <https://doi.org/10.1080/00031305.2017.1356374>`_,
        The American Statistician, 2019, 73, 2, 191-194.
    """
    valid = np.isfinite(x) & np.isfinite(sf)
    if not np.any(valid):
        warnings.warn("No valid values for numerical integration")
        return np.nan
    if n < 1 or np.any(np.modf(n)[0] != 0):
        raise ValueError(
            "The moment order, `n` ({}), must be a positive integer".format(n)
        )
    integrand = x[valid] ** (n - 1)
    integrand *= sf[valid]
    integral = np.trapz(y=integrand, x=x[valid])
    integral *= n
    return integral


def skewness(mu2, mu3):
    r"""
    Calculate the skewness of a distribution from the second and third
    central moment.

    .. math::

        \gamma_1 = \frac{\mu_3}{\mu_2^{3/2}}

    Here, :math:`\mu_n = \langle (x - \mu)^n \rangle` is the
    :math:`n`-th central moment.

    Parameters
    ----------
    mu2, mu3 : scalar or array_like
        The second and third central moment.

    Returns
    -------
    skew : scalar or numpy.ndarray
        The skewness of the distribution.

    Notes
    -----
    If more than one input argument is an array, all arrays must be
    broadcastable.
    """
    return np.divide(mu3, np.power(mu2, 3 / 2))


def kurtosis(mu2, mu4):
    r"""
    Calculate the excess kurtosis (according to Fisher) of a
    distribution from the second and fourth central moment.

    .. math::

        \gamma_2 = \frac{\mu_4}{\mu_2^2} - 3

    Here, :math:`\mu_n = \langle (x - \mu)^n \rangle` is the
    :math:`n`-th central moment.

    Parameters
    ----------
    mu2, mu4 : scalar or array_like
        The second and fourth central moment.

    Returns
    -------
    kurt : scalar or numpy.ndarray
        The excess kurtosis of the distribution.

    Notes
    -----
    If more than one input argument is an array, all arrays must be
    broadcastable.
    """
    return np.divide(mu4, np.power(mu2, 2)) - 3


def integral_method(surv_funcs, times, n_moms=4, int_thresh=0.01):
    r"""
    Estimate characteristics of the underlying lifetime distribution by
    numerically integrating/evaluating the survival function.

    Take a survival function and calculate the raw moments of the
    underlying lifetime distribution by numerically integrating the
    survival function according to the alternative expectation formula
    (see :func:`raw_moment_integrate` for more details).  The standard
    deviation, skewness and excess kurtosis are calculated from the raw
    moments.  The median is estimated as the lag time at which the
    survival function decays below 0.5.

    Parameters
    ----------
    surv_funcs : array_like
        Array of shape ``(t, s)`` where ``t`` is the number of lag times
        and ``s`` is the number of different states.  The ij-th element
        of `surv_funcs` is the value of the survival function of state
        j after a lag time of i frames.
    times : array_like
        Array of shape ``(t,)`` containing the corresponding lag times.
    n_moms : int, optional
        Number of moments to calculate.  Must be greater than zero.
    int_thresh : float, optional
        Only calculate raw moments by numerical integration if the
        survival function decays below the given threshold.

    Returns
    -------
    characs : numpy.ndarray
        Array of shape ``(5 + n_moms-1, )`` containing the following
        distribution characteristics:

            1. Mean (1st raw moment)
            2. 2nd raw moment
            3. 3rd raw moment
            4. 4th raw moment
            5. Standard deviation
            6. Skewness
            7. Excess kurtosis (according to Fisher)
            8. Median

        The number of calculated raw moments depends on `n_moms`.  The
        first raw moment (mean) is always calculated.
    """
    surv_funcs = np.asarray(surv_funcs)
    times = np.asarray(times)
    if surv_funcs.ndim != 2:
        raise ValueError(
            "`surv_funcs` must be 2-dimensional but is"
            " {}-dimensional".format(surv_funcs.ndim)
        )
    if times.shape != surv_funcs.shape[:1]:
        raise ValueError(
            "`times.shape` ({}) != `surv_funcs.shape[:1]`"
            " ({})".format(times.shape, surv_funcs.shape[:1])
        )
    if n_moms < 1:
        raise ValueError(
            "`n_moms` ({}) must be greater than zero".format(n_moms)
        )

    n_frames, n_states = surv_funcs.shape
    characs = np.full((n_states, 4 + n_moms), np.nan, dtype=np.float64)
    for i, sf in enumerate(surv_funcs.T):
        raw_moms = np.full(n_moms, np.nan, dtype=np.float64)
        cen_moms = np.full_like(raw_moms)
        if np.any(sf <= int_thresh):
            # Only calculate the moments by numerical integration if the
            # survival function decays below the given threshold.
            for n in range(len(raw_moms)):
                raw_moms[n] = raw_moment_integrate(sf=sf, x=times, n=n + 1)
                cen_moms[n] = mdt.stats.moment_raw2cen(raw_moms[: n + 1])
        skew = skewness(mu2=cen_moms[1], mu3=cen_moms[2])
        kurt = kurtosis(mu2=cen_moms[1], mu4=cen_moms[3])
        median = cross(y=0.5, x=times, f=sf)
        characs[i] = np.array(
            [*raw_moms, np.sqrt(cen_moms[1]), skew, kurt, median]
        )
    return characs


def get_fit_region(surv_funcs, times, end_fit=None, stop_fit=0.01):
    """
    Get the start and end points of the region within which to fit the
    survival function.

    Parameters
    ----------
    surv_funcs : array_like
        Array of shape ``(t, s)`` where ``t`` is the number of lag times
        and ``s`` is the number of different states.  The ij-th element
        of `surv_funcs` is the value of the survival function of state
        j after a lag time of i frames.
    times : array_like
        Array of shape ``(t,)`` containing the corresponding lag times.
    end_fit : float or None, optional
        End time for fitting.  If None, the fit ends at 90% of the lag
        times.
    stop_fit : float, optional
        Stop fitting the survival function as soon as it falls below the
        given value.  The fitting is stopped by whatever happens
        earlier: `end_fit` or `stop_fit`.

    Returns
    -------
    fit_start_ix, fit_stop_ix : numpy.ndarray
        1-dimensional arrays containing for each state the index of the
        start (inclusive) and end point (exclusive) of the region to
        fit.
    """
    surv_funcs = np.asarray(surv_funcs)
    times = np.asarray(times)
    if surv_funcs.ndim != 2:
        raise ValueError(
            "`surv_funcs` must be 2-dimensional but is"
            " {}-dimensional".format(surv_funcs.ndim)
        )
    if times.shape != surv_funcs.shape[:1]:
        raise ValueError(
            "`times.shape` ({}) != `surv_funcs.shape[:1]`"
            " ({})".format(times.shape, surv_funcs.shape[:1])
        )

    if end_fit is None:
        end_fit_ix = int(0.9 * len(times))
    else:
        _, end_fit_ix = mdt.nph.find_nearest(times, end_fit, return_index=True)
    end_fit_ix += 1  # Make `end_fit_ix` inclusive.

    fit_start_ix = np.zeros(data.shape[1], dtype=np.uint32)  # Inclusive.
    fit_stop_ix = np.zeros(data.shape[1], dtype=np.uint32)  # Exclusive.
    for i, dat in enumerate(data.T):
        stop_fit_ix = np.nanargmax(dat < stop_fit)
        if dat[stop_fit_ix] >= stop_fit:
            # The remain probability never falls below `stop_fit`.
            stop_fit_ix = len(dat)
        elif stop_fit_ix < 2:
            # The remain probability immediately falls below `stop_fit`.
            stop_fit_ix = 2
        fit_stop[i] = min(end_fit_ix, stop_fit_ix)
    return fit_start_ix, fit_stop_ix


def fit_goodness(data, fit):
    """
    Calculate quantities to assess the goodness of a fit.

    Parameters
    ----------
    data : array_like
        The true data.
    fit : array_like
        Array of the same shape as `data` containing the corresponding
        fit/model values.

    Returns
    -------
    r2 : scalar
        (Pseudo) coefficient of determination.  See
        https://www.r-bloggers.com/2021/03/the-r-squared-and-nonlinear-regression-a-difficult-marriage.
    rmse : scalar
        The root-mean-square error, also known as root-mean-square
        residuals.
    """
    data = np.asarray(data)
    fit = np.asarray(fit)
    if fit.shape != data.shape:
        raise ValueError(
            "`fit.shape` ({}) != `data.shape`"
            " ({})".format(fit.shape, data.shape)
        )

    # Residual sum of squares.
    ss_res = np.sum((data - fit) ** 2)
    # Root-mean-square error / root-mean-square residuals.
    rmse = np.sqrt(ss_res / len(fit))
    # Total sum of squares.
    ss_tot = np.sum((data - np.mean(data)) ** 2)
    # (Pseudo) coefficient of determination (R^2).
    r2 = 1 - (ss_res / ss_tot)
    return r2, rmse


def weibull_fit_method(
    surv_funcs,
    times,
    fit_start,
    fit_stop,
    surv_funcs_var=None,
    n_moms=4,
    fit_method="trf",
):
    r"""
    Estimate characteristics of the underlying lifetime distribution
    assuming a Weibull distribution.

    Take a survival function and fit it with the survival function of a
    Weibull distribution.  Characteristics of the underlying lifetime
    distribution are thus described by characteristics of the fitted
    Weibull distribution.

    Parameters
    ----------
    surv_funcs : array_like
        Array of shape ``(t, s)`` where ``t`` is the number of lag times
        and ``s`` is the number of different states.  The ij-th element
        of `surv_funcs` is the value of the survival function of state
        j after a lag time of i frames.
    times : array_like
        Array of shape ``(t,)`` containing the corresponding lag times.
    fit_start_ix, fit_stop_ix : numpy.ndarray
        1-dimensional arrays containing for each state the index of the
        start (inclusive) and end point (exclusive) of the region to
        fit.
    surv_funcs_var : array_like or None, optional
        Array of the same shape as `surv_funcs` containing the variance
        of the survival function.
    n_moms : int, optional
        Number of moments to calculate.  Must be greater than zero.
    fit_method : str, optional
        Fit method of :func:`scipy.optimize.curve_fit` to use for
        fitting the survival function.  See there for possible options.

    Returns
    -------
    characs : numpy.ndarray
        Array of shape ``(5 + n_moms-1, )`` containing the following
        distribution characteristics:

            1. Mean (1st raw moment)
            2. 2nd raw moment
            3. 3rd raw moment
            4. 4th raw moment
            5. Standard deviation
            6. Skewness
            7. Excess kurtosis (according to Fisher)
            8. Median

        The number of calculated raw moments depends on `n_moms`.  The
        first raw moment (mean) is always calculated.
    fit_quality : numpy.ndarray
        Array that contains quantities to assess the goodness of a fit.
        See :func:`fit_goodness` for details about the calculated
        quantities.
    popt : numpy.ndarray
        Optimal values for the fit parameters so that the sum of the
        squared residuals is minimized.  The first element of `popt` is
        the optimal :math:`\tau_0` value, the second element is the
        optimal :math:`\beta` value.
    perr : numpy.ndarray
        Standard deviation of the optimal parameters.

    See Also
    --------
    :func:`mdtools.fit.fit_kww` :
        The function that is used to fit the survival functions.

    Notes
    -----
    The probability distribution function of the Weibull distribution is
    given by

    .. math::

        f(t) =
        \frac{\beta}{\tau_0}
        \left( \frac{t}{\tau_0} \right)^{\beta - 1}
        \exp{\left[ \left( -\frac{t}{\tau_0} \right)^\beta \right]}

    It is a special form of the generalized gamma distribution with
    :math:`\delta = \beta`.

    .. math::

        f(t) =
        \frac{1}{\Gamma\left( \frac{\delta}{\beta} \right)}
        \frac{\beta}{\tau_0}
        \left( \frac{t}{\tau_0} \right)^{\delta - 1}
        \exp{\left[ \left( -\frac{t}{\tau_0} \right)^\beta \right]}

    If :math:`\beta = 1`, the Weibull distribution reduces to the
    exponential distribution.

    The survival function of the Weibull distribution is a stretched
    exponential, also known as Kohlrausch or Kohlrausch- Williams-Watts
    (KWW) function:

    .. math::

        S(t) = \exp\left[ -\left(\frac{t}{\tau_0})^\beta \right) \right]

    The :math:`n`-th raw moment of the Weibull distribution is

    .. math::

        \langle t^n \rangle = \tau_0^n \Gamma(1 + \frac{n}{\beta})

    The median of the Weibull distribution is

    .. math::

        t_med = tau_0 * \left[ \len(2) \right]^\frac{1}{\beta}

    The skewness of the Weibull distribution is

    .. math::

        \gamma_1 =
        \frac{
             2 \Gamma^3\left( 1 + \frac{1}{\beta} \right)
            -3 \Gamma  \left( 1 + \frac{1}{\beta} \right)
               \Gamma  \left( 1 + \frac{2}{\beta} \right)
            +  \Gamma  \left( 1 + \frac{3}{\beta} \right)
        }{
            \left[
                 \Gamma  \left( 1 + \frac{2}{\beta} \right)
                -\Gamma^2\left( 1 + \frac{1}{\beta} \right)
            \right]^{3/2}
        }

    The excess kurtosis (according to Fisher) of the Weibull
    distribution is

    .. math::

        \gamma_2 =
        \frac{
             -6 \Gamma^4\left( 1 + \frac{1}{\beta} \right)
            +12 \Gamma^2\left( 1 + \frac{1}{\beta} \right)
                \Gamma  \left( 1 + \frac{2}{\beta} \right)
             -3 \Gamma^2\left( 1 + \frac{2}{\beta} \right)
             -4 \Gamma  \left( 1 + \frac{1}{\beta} \right)
                \Gamma  \left( 1 + \frac{3}{\beta} \right)
             +  \Gamma  \left( 1 + \frac{4}{\beta} \right)
        }{
            \left[
                 \Gamma  \left( 1 + \frac{2}{\beta} \right) -
                -\Gamma^2\left( 1 + \frac{1}{\beta} \right)
            \right]^2
        }

    """
    surv_funcs = np.asarray(surv_funcs)
    times = np.asarray(times)
    fit_start = np.asarray(fit_start)
    fit_stop = np.asarray(fit_stop)
    if surv_funcs.ndim != 2:
        raise ValueError(
            "`surv_funcs` must be 2-dimensional but is"
            " {}-dimensional".format(surv_funcs.ndim)
        )
    if times.shape != surv_funcs.shape[:1]:
        raise ValueError(
            "`times.shape` ({}) != `surv_funcs.shape[:1]`"
            " ({})".format(times.shape, surv_funcs.shape[:1])
        )
    if fit_start.shape != surv_funcs.shape[1:]:
        raise ValueError(
            "fit_start.shape ({}) != surv_funcs.shape[1:]"
            " ({})".format(fit_start.shape, surv_funcs.shape[1:])
        )
    if fit_stop.shape != fit_start.shape:
        raise ValueError(
            "fit_stop.shape ({}) != fit_start.shape"
            " ({})".format(fit_stop.shape, fit_start.shape)
        )
    if n_moms < 1:
        raise ValueError(
            "`n_moms` ({}) must be greater than zero".format(n_moms)
        )

    if surv_funcs_var is not None:
        surv_funcs_sd = np.sqrt(surv_funcs_var)
        if surv_funcs_sd.shape != surv_funcs.shape:
            raise ValueError(
                "surv_funcs_var.shape ({}) != surv_funcs.shape"
                " ({})".format(surv_funcs_sd.shape, surv_funcs.shape)
            )
    else:
        surv_funcs_sd = None

    n_frames, n_states = surv_funcs.shape
    bounds = ([0, 0], [np.inf, np.inf])
    popt = np.full((n_states, 2), np.nan, dtype=np.float64)
    perr = np.full_like(popt, np.nan)
    fit_quality = np.full((n_states, 2), np.nan, dtype=np.float64)
    characs = np.full((n_states, 8), np.nan, dtype=np.float64)
    for i, sf in enumerate(surv_funcs.T):
        # Do the fit.
        times_fit = times[fit_start[i] : fit_stop[i]]
        sf_fit = sf[fit_start[i] : fit_stop[i]]
        popt[i], perr[i], valid = mdt.func.fit_kww(
            xdata=times_fit,
            ydata=sf_fit,
            ysd=surv_funcs_sd,
            return_valid=True,
            bounds=bounds,
            method=fit_method,
        )
        fit = mdt.func.kww(times_fit[valid], *popt[i])
        fit_quality[i] = np.array(fit_goodness(data=sf_fit[valid], fit=fit))
        # Calculate distribution characteristics.
        dist = stats.gengamma(
            a=1,  # delta/beta = beta/beta = 1.
            c=popt[i, 1],  # beta.
            loc=0,
            scale=popt[i, 0],  # tau0.
        )
        raw_moms = [dist.moment(n) for n in range(1, n_moms + 1)]
        var, skew, kurt = dist.stats(moments="vsk")
        characs[i] = np.array(
            [*raw_moms, np.sqrt(var), skew, kurt, dist.median()]
        )
    return characs, fit_quality, popt, perr


def burr12_fit_method(
    surv_funcs,
    times,
    fit_start,
    fit_stop,
    surv_funcs_var=None,
    n_moms=4,
    fit_method="trf",
):
    r"""
    Estimate characteristics of the underlying lifetime distribution
    assuming a Burr Type XII distribution.

    Take a survival function and fit it with the survival function of a
    Burr Type XII distribution.  Characteristics of the underlying
    lifetime distribution are thus described by characteristics of the
    fitted Burr Type XII distribution.

    Parameters
    ----------
    surv_funcs : array_like
        Array of shape ``(t, s)`` where ``t`` is the number of lag times
        and ``s`` is the number of different states.  The ij-th element
        of `surv_funcs` is the value of the survival function of state
        j after a lag time of i frames.
    times : array_like
        Array of shape ``(t,)`` containing the corresponding lag times.
    fit_start_ix, fit_stop_ix : numpy.ndarray
        1-dimensional arrays containing for each state the index of the
        start (inclusive) and end point (exclusive) of the region to
        fit.
    surv_funcs_var : array_like or None, optional
        Array of the same shape as `surv_funcs` containing the variance
        of the survival function.
    n_moms : int, optional
        Number of moments to calculate.  Must be greater than zero.
    fit_method : str, optional
        Fit method of :func:`scipy.optimize.curve_fit` to use for
        fitting the survival function.  See there for possible options.

    Returns
    -------
    characs : numpy.ndarray
        Array of shape ``(5 + n_moms-1, )`` containing the following
        distribution characteristics:

            1. Mean (1st raw moment)
            2. 2nd raw moment
            3. 3rd raw moment
            4. 4th raw moment
            5. Standard deviation
            6. Skewness
            7. Excess kurtosis (according to Fisher)
            8. Median

        The number of calculated raw moments depends on `n_moms`.  The
        first raw moment (mean) is always calculated.
    fit_quality : numpy.ndarray
        Array that contains quantities to assess the goodness of a fit.
        See :func:`fit_goodness` for details about the calculated
        quantities.
    popt : numpy.ndarray
        Optimal values for the fit parameters so that the sum of the
        squared residuals is minimized.  The first element of `popt` is
        the optimal :math:`\tau_0` value, the second element is the
        optimal :math:`\beta` value, the third value is the optimal
        :math:`d` value, where :math:`d = \beta\delta` (!).
    perr : numpy.ndarray
        Standard deviation of the optimal parameters.
    popt_converted : numpy.ndarray
        Same as `popt`, but instead of :math:`d = \beta\delta`, the
        third value is :math:`\delta`.
    perr_converted : numpy.ndarray
        Standard deviation of `popt_converted`.

    See Also
    --------
    :func:`mdtools.fit.fit_burr12_sf_alt` :
        The function that is used to fit the survival functions.

    Notes
    -----
    The probability distribution function of the Burr Type XII
    distribution is given by

    .. math::

        f(t) =
        \frac{\beta \delta}{\tau_0}
        \left( \frac{t}{\tau_0} \right)^{\beta - 1}
        \frac{
            1
        }{
            \left[
                1 + \left( \frac{t}{\tau_0} \right)^\beta
            \right]^{\delta - 1}
        }

    If :math:`\delta = 1`, the Burr Type XII distribution reduces to the
    log-logistic distribution.  If :math:`\beta = 1`, the Burr Type XII
    distribution reduces to the Lomax distribution.

    The survival function of the Burr Type XII distribution is

    .. math::

        S(t) =
        \frac{
            1
        }{
            \left[
                1 + \left( \frac{t}{\tau_0} \right)^\beta
            \right]^\delta
        }

    For :math:`\beta = 1`, the survival function is also known as
    Becquerel decay.

    The :math:`n`-th raw moment of the Burr Type XII distribution is

    .. math::

        \langle t^n \rangle =
        \tau_0^n
        \frac{
            \Gamma\left( \delta - \frac{n}{\beta} \right)
            \Gamma\left( 1      + \frac{n}{\beta} \right)
        }{
            \Gamma(\delta)
        }

    Note that the n-th raw moment of the Burr Type XII distribution only
    exists if :math:`n < \beta \delta`.

    The median of the Burr Type XII distribution is

    .. math::

        t_med = \frac{1}{\left( 2^{1/\delta} - 1 \right)^(1/\beta)}

    """
    surv_funcs = np.asarray(surv_funcs)
    times = np.asarray(times)
    fit_start = np.asarray(fit_start)
    fit_stop = np.asarray(fit_stop)
    if surv_funcs.ndim != 2:
        raise ValueError(
            "`surv_funcs` must be 2-dimensional but is"
            " {}-dimensional".format(surv_funcs.ndim)
        )
    if times.shape != surv_funcs.shape[:1]:
        raise ValueError(
            "`times.shape` ({}) != `surv_funcs.shape[:1]`"
            " ({})".format(times.shape, surv_funcs.shape[:1])
        )
    if fit_start.shape != surv_funcs.shape[1:]:
        raise ValueError(
            "fit_start.shape ({}) != surv_funcs.shape[1:]"
            " ({})".format(fit_start.shape, surv_funcs.shape[1:])
        )
    if fit_stop.shape != fit_start.shape:
        raise ValueError(
            "fit_stop.shape ({}) != fit_start.shape"
            " ({})".format(fit_stop.shape, fit_start.shape)
        )
    if n_moms < 1:
        raise ValueError(
            "`n_moms` ({}) must be greater than zero".format(n_moms)
        )

    if surv_funcs_var is not None:
        surv_funcs_sd = np.sqrt(surv_funcs_var)
        if surv_funcs_sd.shape != surv_funcs.shape:
            raise ValueError(
                "surv_funcs_var.shape ({}) != surv_funcs.shape"
                " ({})".format(surv_funcs_sd.shape, surv_funcs.shape)
            )
    else:
        surv_funcs_sd = None

    n_frames, n_states = surv_funcs.shape
    bounds = ([0, 0, 1 + 1e-6], [np.inf, np.inf, np.inf])
    popt = np.full((n_states, 3), np.nan, dtype=np.float64)
    perr = np.full_like(popt, np.nan)
    fit_quality = np.full((n_states, 2), np.nan, dtype=np.float64)
    characs = np.full((n_states, 8), np.nan, dtype=np.float64)
    for i, sf in enumerate(surv_funcs.T):
        # Do the fit.
        times_fit = times[fit_start[i] : fit_stop[i]]
        sf_fit = sf[fit_start[i] : fit_stop[i]]
        popt[i], perr[i], valid = mdt.func.fit_burr12_sf_alt(
            xdata=times_fit,
            ydata=sf_fit,
            ysd=surv_funcs_sd,
            return_valid=True,
            bounds=bounds,
            method=fit_method,
        )
        fit = mdt.func.burr12_sf_alt(times_fit[valid], *popt[i])
        fit_quality[i] = np.array(fit_goodness(data=sf_fit[valid], fit=fit))
        # Calculate distribution characteristics.
        dist = stats.burr12(
            c=popt[i, 1],  # beta.
            d=popt[i, 2] / popt[i, 1],  # delta.
            loc=0,
            scale=popt[i, 0],  # tau0.
        )
        raw_moms = [dist.moment(n) for n in range(1, n_moms + 1)]
        var, skew, kurt = dist.stats(moments="vsk")
        characs[i] = np.array(
            [*raw_moms, np.sqrt(var), skew, kurt, dist.median()]
        )

    tau0, beta, d = popt.T
    tau0_sd, beta_sd, d_sd = perr.T
    delta = d / beta
    delta_sd = np.sqrt(  # Propagation of uncertainty.
        delta**2
        * (
            (d_sd / d) ** 2
            + (beta_sd / beta) ** 2
            - 2 * d_sd * beta_sd / (d * beta)
        )
    )
    popt_converted = np.column_stack([tau0, beta, delta])
    perr_converted = np.column_stack([tau0_sd, beta_sd, delta_sd])
    return characs, fit_quality, popt, perr, popt_converted, perr_converted


def get_ydata_min_max(ax):
    """
    Get the minimum and maximum y value of the data plotted in an
    :class:`matplotlib.axes.Axes`.

    Parameters
    ----------
    ax : matplotlib.axes.Axes
        The :class:`~matplotlib.axes.Axes` from which to get the data.

    Returns
    -------
    yd_min, yd_max : numpy.ndarray
        Array of minimum and maximum values of the y data plotted in the
        given :class:`~matplotlib.axes.Axes`.  Each value in the array
        corresponds to one plotted :class:`matplotlib.lines.Line2D` in
        the :class:`~matplotlib.axes.Axes`.
    """
    ydata = [line.get_ydata() for line in ax.get_lines()]
    yd_min, yd_max = [], []
    for yd in ydata:
        if isinstance(yd, np.ndarray) and np.any(yd > 0):
            yd_min.append(np.min(yd[yd > 0]))
            yd_max.append(np.max(yd[yd > 0]))
    yd_min, yd_max = np.array(yd_min), np.array(yd_max)
    return yd_min, yd_max


if __name__ == "__main__":  # noqa: C901
    timer_tot = datetime.now()
    proc = psutil.Process()
    proc.cpu_percent()  # Initiate monitoring of CPU usage.
    parser = argparse.ArgumentParser(
        # The description should only contain the short summary from the
        # docstring and a reference to the documentation.
        description=(
            "Compare state lifetimes calculated from a discrete trajectory"
            " using different methods"
        )
    )
    parser.add_argument(
        "--dtrj",
        dest="INFILE_DTRJ",
        type=str,
        required=True,
        help=(
            "File containing the discrete trajectory stored as numpy.ndarray"
            " in the binary .npy format or as .npz archive."
        ),
    )
    parser.add_argument(
        "--rp",
        dest="INFILE_RP",
        type=str,
        required=True,
        help=(
            "Name of the file containing the remain probabilities for each"
            " state."
        ),
    )
    parser.add_argument(
        "--km",
        dest="INFILE_KM",
        type=str,
        required=True,
        help=(
            "Name of the file containing the Kaplan-Meier estimate of the"
            " survival function for each state."
        ),
    )
    parser.add_argument(
        "--param",
        dest="INFILE_PARAM",
        type=str,
        required=False,
        default=None,
        help=(
            "File containing the parameters that were used to generate the"
            " artificial discrete trajectory (optional)."
        ),
    )
    parser.add_argument(
        "-o",
        dest="OUTFILE",
        type=str,
        required=True,
        help="Output filename pattern.",
    )
    parser.add_argument(
        "--int-thresh",
        dest="INT_THRESH",
        type=float,
        required=False,
        default=0.01,
        help=(
            "Only calculate the lifetime by directly integrating the estimated"
            " survival function if the survival function decays below the"
            " given threshold.  Default:  %(default)s."
        ),
    )
    parser.add_argument(
        "--end-fit",
        dest="ENDFIT",
        type=float,
        required=False,
        default=None,
        help=(
            "End time for fitting the survival function in trajectory steps"
            " (inclusive).  If None, the fit ends at 90%% of the lag times."
            "  Default: %(default)s."
        ),
    )
    parser.add_argument(
        "--stop-fit",
        dest="STOPFIT",
        type=float,
        required=False,
        default=0.01,
        help=(
            "Stop fitting the survival function as soon as it falls below the"
            " given value.  The fitting is stopped by whatever happens"
            " earlier: --end-fit or --stop-fit.  Default: %(default)s."
        ),
    )
    parser.add_argument(
        "--time-conv",
        dest="TIME_CONV",
        type=float,
        required=False,
        default=1,
        help="Time conversion factor.  Default: %(default)s.",
    )
    args = parser.parse_args()
    print(mdt.rti.run_time_info_str())

    # Number of moments to calculate.  For calculating the skewness, the
    # 2nd and 3rd (central) moments are required, for the kurtosis the
    # 2nd and 4th (central) moments are required.
    n_moms = 4
    # Fit method of `scipy.optimize.curve_fit` to use for all fits.
    fit_method = "trf"

    ####################################################################
    print("\n")
    print("Calculating lifetimes directly from `dtrj`...")
    timer = datetime.now()
    dtrj = mdt.fh.load_dtrj(args.INFILE_DTRJ)
    n_frames = dtrj.shape[1]
    # Method 1: Censored counting.
    lts_cnt_cen_characs, states = count_method(
        dtrj, uncensored=False, time_conv=args.TIME_CONV, states=None
    )
    n_states = len(states)
    # Method 2: Uncensored counting.
    lts_cnt_unc_characs, _states = count_method(
        dtrj, uncensored=True, time_conv=args.TIME_CONV, states=states
    )
    del _states
    # Method 3: Calculate the transition rate as the number of
    # transitions leading out of a given state divided by the number of
    # frames that compounds have spent in this state.  The average
    # lifetime is calculated as the inverse transition rate.
    rates, states_k = mdt.dtrj.trans_rate_per_state(dtrj, return_states=True)
    lts_k = args.TIME_CONV / rates
    if not np.array_equal(states_k, states):
        raise ValueError(
            "`states_k` ({}) != `states` ({})".format(states_k, states)
        )
    del dtrj, rates, states_k
    print("Elapsed time:         {}".format(datetime.now() - timer))
    print("Current memory usage: {:.2f} MiB".format(mdt.rti.mem_usage(proc)))
    ####################################################################

    ####################################################################
    print("\n")
    print("Calculating lifetimes from the remain probability...")
    timer = datetime.now()
    # Read remain probabilities from file.
    remain_props, times, _states = read_sf_from_file(
        args.INFILE_RP,
        time_conv=args.TIME_CONV,
        n_frames=n_frames,
        states=states,
    )
    del _states
    # Method 4: Numerical integration of the remain probability.
    lts_rp_int_characs = integral_method(
        remain_props, times, n_moms=n_moms, int_thresh=args.INT_THRESH
    )
    # Get fit region for fitting methods.
    fit_start, fit_stop = get_fit_region(
        remain_props, times, end_fit=args.ENDFIT, stop_fit=args.STOPFIT
    )
    # Method 5: Weibull fit of the remain probability.
    (
        lts_rp_wbl_characs,
        lts_rp_wbl_fit_goodness,
        popt_rp_wbl,
        perr_rp_wbl,
    ) = weibull_fit_method(
        remain_props,
        times,
        fit_start=fit_start,
        fit_stop=fit_stop,
        n_moms=n_moms,
        fit_method=fit_method,
    )
    tau0_rp_wbl, beta_rp_wbl = popt_rp_wbl.T
    tau0_rp_wbl_sd, beta_rp_wbl_sd = perr_rp_wbl.T
    # Method 6: Burr Type XII fit of the remain probability.
    (
        lts_rp_brr_characs,
        lts_rp_brr_fit_goodness,
        popt_rp_brr,
        perr_rp_brr,
        popt_conv_rp_brr,
        perr_conv_rp_brr,
    ) = burr12_fit_method(
        remain_props,
        times,
        fit_start=fit_start,
        fit_stop=fit_stop,
        n_moms=n_moms,
        fit_method=fit_method,
    )
    tau0_rp_brr, beta_rp_brr, delta_rp_brr = popt_conv_rp_brr.T
    tau0_rp_brr_sd, beta_rp_brr_sd, delta_rp_brr_sd = perr_conv_rp_brr.T
    print("Elapsed time:         {}".format(datetime.now() - timer))
    print("Current memory usage: {:.2f} MiB".format(mdt.rti.mem_usage(proc)))
    ####################################################################

    ####################################################################
    print("\n")
    print("Calculating lifetimes from the Kaplan-Meier estimator...")
    timer = datetime.now()
    # TODO
    # Read Kaplan-Meier survival functions from file.
    # Method 7: Numerical integration of the Kaplan-Meier estimator.
    # Get fit region for fitting methods.
    # Method 8: Weibull fit of the Kaplan-Meier estimator.
    # Method 9: Burr Type XII fit of the Kaplan-Meier estimator.
    print("Elapsed time:         {}".format(datetime.now() - timer))
    print("Current memory usage: {:.2f} MiB".format(mdt.rti.mem_usage(proc)))
    ####################################################################

    ####################################################################
    if args.INFILE_PARAM is not None:
        print("\n")
        print("Reading true lifetimes from parameters file...")
        params = np.loadtxt(args.INFILE_PARAM, usecols=np.arange(4))
        states_true = params[:, 0]
        if not np.all(np.isin(states, states_true)):
            raise ValueError(
                "`states` ({}) is not fully contained in `states_true`"
                " ({})".format(states, states_true)
            )
        del states_true
        params = params[states]
        # Parameters of the true lifetime distribution.
        beta_true, delta_true, tau0_true = params[:, 1:4].T
        dist_params = np.column_stack([tau0_true, beta_true, delta_true])

        # Lifetime distributions used to generate the trajectory.
        dist = None
        with mdt.fh.xopen(args.INFILE_PARAM, "r") as file:
            for line in file.readlines():
                if line.startswith("# Lifetime dist.:"):
                    dist = line.split()[-1]
                    break
        if dist is None:
            raise ValueError(
                "Could not determine the used lifetime distribution from"
                " {}".format(args.INFILE_PARAM)
            )
        elif dist == "generalized_gamma":
            lt_dists = [
                stats.gengamma(
                    a=delta_true[i] / beta_true[i],
                    c=beta_true[i],
                    loc=0,
                    scale=tau0_true[i],
                )
                for i in range(n_states)
            ]
        elif dist == "burr12":
            lt_dists = [
                stats.burr12(
                    c=beta_true[i], d=delta_true[i], loc=0, scale=tau0_true[i]
                )
                for i in range(n_states)
            ]
        else:
            raise ValueError("Unknown lifetime distribution: {}".format(dist))

        lts_true_rp_goodness = np.full((n_states, 2), np.nan, dtype=np.float64)
        lts_true_characs = np.full((n_states, 5), np.nan, dtype=np.float64)
        for i, rp in enumerate(remain_props.T):
            # R^2 and RMSE if the remain probability is seen as fit of
            # the true survival function.
            valid = np.isfinite(rp)
            sf_true = lt_dists[i].sf(times[valid])
            r2, rmse = fit_goodness(data=sf_true, fit=rp[valid])
            lts_true_rp_goodness[i] = np.array([r2, rmse])
            # Calculate distribution characteristics.
            lts_true_characs[i] = np.array(
                [
                    # Mean, variance, skewness, kurtosis.
                    *lt_dists[i].stats("mvsk"),
                    # Median
                    lt_dists[i].median(),
                ]
            )
            # Variance -> Standard deviation.
            lts_true_characs[i, 1] = np.sqrt(lts_true_characs[i, 1])
    ####################################################################

    ####################################################################
    print("\n")
    print("Creating text output...")
    timer = datetime.now()
    data = [
        states,  # 1
        # Method 1 (censored counting).
        lts_cnt_cen_characs,  # 2-10
        # Method 2 (uncensored counting).
        lts_cnt_unc_characs,  # 11-19
        # Method 3 (inverse transition rate).
        lts_k,  # 20
        # Method 4 (1/e criterion).
        lts_e,  # 21
        # Method 5 (direct integral).
        lts_int_characs,  # 22-26
        # Method 6 (integral of Kohlrausch fit).
        lts_kww_characs,  # 27-31
        tau0_kww,  # 32
        tau0_kww_sd,  # 33
        beta_kww,  # 34
        beta_kww_sd,  # 35
        lts_kww_fit_goodness,  # 36-37
        # Method 7 (integral of Burr fit).
        lts_bur_characs,  # 38-42
        tau0_bur,  # 43
        tau0_bur_sd,  # 44
        beta_bur,  # 45
        beta_bur_sd,  # 46
        delta_bur,  # 47
        delta_bur_sd,  # 48
        lts_bur_fit_goodness,  # 49-50
        # Fit region
        fit_start,  # 51
        fit_stop - 1,  # 52
    ]
    if args.INFILE_PARAM is not None:
        data += [
            lts_true_characs,  # 53-57
            dist_params,  # 58-60
            lts_true_rp_goodness,  # 61-62
        ]
    data = np.column_stack(data)
    header = (
        "State lifetimes.\n"
        + "Average time that a given compound stays in a given state\n"
        + "calculated either directly from the discrete trajectory\n"
        + "(Method 1-3) or from the corresponding remain probability\n"
        + "function (Method 4-7). \n"
        + "\n"
        + "\n"
        + "Discrete trajectory: {:s}\n".format(args.INFILE_DTRJ)
        + "Remain probability:  {:s}\n".format(args.INFILE_RP)
    )
    if args.INFILE_PARAM is not None:
        header += (
            "Parameter file:      {:s}\n".format(args.INFILE_PARAM)
            + "\n"
            + "\n"
        )
    header += (
        "Lifetimes are calculated using different methods:\n"
        + "\n"
        + "1) The average lifetime <t_cnt_cen> is calculated by counting how\n"
        + "   many frames a given compound stays in a given state including\n"
        + "   truncated states at the trajectory edges -> censored counting.\n"
        + "   Note that lifetimes calculated in this way are usually biased\n"
        + "   to lower values because of the limited length of the\n"
        + "   trajectory and because of truncation/censoring at the\n"
        + "   trajectory edges.\n"
        + "\n"
        + "2) The average lifetime <t_cnt_unc> is calculated by counting how\n"
        + "   many frames a given compound stays in a given state excluding\n"
        + "   truncated states at the trajectory edges -> uncensored\n"
        + "   counting.  Note that lifetimes calculated in this way are\n"
        + "   usually biased to lower values because of the limited length\n"
        + "   of the trajectory.  Uncensored counting might waste a\n"
        + "   significant amount of the trajectory.\n"
        + "\n"
        + "3) The average transition rate <k> is calculated as the number of\n"
        + "   transitions leading out of a given state divided by the number\n"
        + "   of frames that compounds have spent in this state.  The\n"
        + "   average lifetime <t_k> is calculated as the inverse transition\n"
        + "   rate:\n"
        + "     <t_k> = 1 / <k>\n"
        + "\n"
        + "4) The average lifetime <t_e> is set to the lag time at which the\n"
        + "   remain probability function p(t) crosses 1/e.  If this never\n"
        + "   happens, <t_e> is set to NaN.\n"
        + "\n"
        + "5) The remain probability function p(t) is interpreted as the\n"
        + "   survival function of the underlying lifetime distribution.\n"
        + "   Thus, the lifetime can be calculated according to the\n"
        + "   alternative expectation formula [1]:\n"
        + "     <t_int^n> = n * int_0^inf t^(n-1) p(t) dt\n"
        + "   If p(t) does not decay below the given threshold of\n"
        + "   {:.4f}, <t_int^n> is set to NaN.\n".format(args.INT_THRESH)
        + "\n"
        + "6) The remain probability function p(t) is fitted by a Kohlrausch\n"
        + "   function (stretched exponential, survival function of the\n"
        + "   Weibull distribution):\n"
        + "     I_kww(t) = exp[-(t/tau0_kww)^beta_kww]\n"
        + "   Thereby, tau0_kww is confined to the interval\n"
        + "   [{:.4f}, {:.4f}] and beta_kww is confined to the\n".format(
            bounds_kww[0][0], bounds_kww[1][0]
        )
        + "   interval [{:.4f}, {:.4f}].\n".format(
            bounds_kww[0][1], bounds_kww[1][1]
        )
        + "   The average lifetime <t_kww^n> is calculated according to the\n"
        + "   alternative expectation formula [1]:\n"
        + "     <t_kww^n> = n * int_0^inf t^(n-1) I_kww(t) dt\n"
        + "               = tau0_kww^n * Gamma(1 + n/beta_kww)\n"
        + "   where Gamma(z) is the gamma function.\n"
        + "\n"
        + "7) The remain probability function p(t) is fitted by the survival\n"
        + "   function of a Burr Type XII distribution:\n"
        + "     I_bur(t) = 1 / [1 + (t/tau0_bur)^beta_bur]^delta_bur\n"
        + "   Thereby, tau0_bur is confined to the interval\n"
        + "   [{:.4f}, {:.4f}], beta_bur is confined to the interval\n".format(
            bounds_bur[0][0], bounds_bur[1][0]
        )
        + "   [{:.4f}, {:.4f}] and beta_bur * delta_bur is confined\n".format(
            bounds_bur[0][1], bounds_bur[1][1]
        )
        + "   to the interval [{:.4f}, {:.4f}].\n".format(
            bounds_bur[0][2], bounds_bur[1][2]
        )
        + "   The average lifetime <t_bur^n> is calculated according to the\n"
        + "   alternative expectation formula [1]:\n"
        + "     <t_bur^n> = n * int_0^inf t^(n-1) I_bur(t) dt\n"
        + "               = tau0_bur^n * Gamma(delta_bur - n/beta_bur) *\n"
        + "                 Gamma(1 + n/beta_bur) / Gamma(delta_bur)\n"
        + "   where Gamma(z) is the gamma function.\n"
        + "\n"
        + "All fits are done using scipy.optimize.curve_fit with the 'Trust\n"
        + "Region Reflective' method.  The remain probability is always\n"
        + "fitted until it decays below the given threshold or until the\n"
        + "given lag time is reached (whatever happens earlier).\n"
        + "\n"
        + "int_thresh = {:.4f}\n".format(args.INT_THRESH)
        + "end_fit  = {}\n".format(args.ENDFIT)
        + "stop_fit = {:.4f}\n".format(args.STOPFIT)
        + "\n"
        + "Reference [1]:\n"
        + "  S. Chakraborti, F. Jardim, E. Epprecht,\n"
        + "  Higher-order moments using the survival function: The\n"
        + "  alternative expectation formula,\n"
        + "  The American Statistician, 2019, 73, 2, 191-194."
        + "\n"
        + "\n"
        + "The columns contain:\n"
        + "  1 State index (zero-based)\n"
        + "\n"
        + "  Lifetime from Method 1 (censored counting)\n"
        + "  2 Sample mean <t_cnt_cen> / frames\n"
        + "  3 Uncertainty of the sample mean (standard error) / frames\n"
        + "  4 Corrected sample standard deviation / frames\n"
        + "  5 Unbiased sample skewness\n"
        + "  6 Unbiased sample excess kurtosis (Fisher)\n"
        + "  7 Sample median / frames\n"
        + "  8 Sample minimum / frames\n"
        + "  9 Sample maximum / frames\n"
        + " 10 Number of observations/samples\n"
        + "\n"
        + "  Lifetime from Method 2 (uncensored counting)\n"
        + " 11-19 As Method 1\n"
        + "\n"
        + "  Lifetime from Method 3 (inverse transition rate)\n"
        + " 20 <t_k> / frames\n"
        + "\n"
        + "  Lifetime from Method 4 (1/e criterion)\n"
        + " 21 <t_e> / frames\n"
        + "\n"
        + "  Lifetime from Method 5 (direct integral)\n"
        + " 22 Mean <t_int> / frames\n"
        + " 23 Standard deviation / frames\n"
        + " 24 Skewness\n"
        + " 25 Excess kurtosis (Fisher)\n"
        + " 26 Median / frames\n"
        + "\n"
        + "  Lifetime from Method 6 (integral of Kohlrausch fit)\n"
        + " 27-31 As Method 5\n"
        + " 32 Fit parameter tau0_kww / frames\n"
        + " 33 Standard deviation of tau0_kww / frames\n"
        + " 34 Fit parameter beta_kww\n"
        + " 35 Standard deviation of beta_kww\n"
        + " 36 Coefficient of determination of the fit (R^2 value)\n"
        + " 37 Root-mean-square error (RMSE) of the fit\n"
        + "\n"
        + "  Lifetime from Method 7 (integral of Burr fit)\n"
        + " 38-46 As Method 6\n"
        + " 47 Fit parameter delta_burr\n"
        + " 48 Standard deviation of delta_burr\n"
        + " 49 Coefficient of determination of the fit (R^2 value)\n"
        + " 50 Root-mean-square error (RMSE) of the fit\n"
        + "\n"
        + "  Fit region for all fitting methods\n"
        + " 51 Start of fit region (inclusive) / frames\n"
        + " 52 End of fit region (inclusive) / frames\n"
    )
    if args.INFILE_PARAM is not None:
        header += (
            "\n"
            + "  True state lifetimes\n"
            + " 53-57 As Method 5\n"
            + " 58 Scale parameter tau0 of the true distribution\n"
            + " 59 Shape parameter beta of the true distribution\n"
            + " 60 Shape parameter delta of the true distribution\n"
            + " 61 R^2 if the remain probability is seen as fit of the\n"
            + "    survival function (SF) of the true distribution\n"
            + " 62 RMSE of the remain probability to the true SF\n"
        )
    header += "\n" + "Column number:\n"
    header += "{:>14d}".format(1)
    for i in range(2, data.shape[-1] + 1):
        header += " {:>16d}".format(i)
    outfile = args.OUTFILE + ".txt"
    mdt.fh.savetxt(outfile, data, header=header)
    print("Created {}".format(outfile))
    print("Elapsed time:         {}".format(datetime.now() - timer))
    print("Current memory usage: {:.2f} MiB".format(mdt.rti.mem_usage(proc)))

    ####################################################################
    print("\n")
    print("Creating plot(s)...")
    timer = datetime.now()

    label_true = "True"
    # label_cen = "True Cens."
    # label_unc = "True Uncen."
    label_cnt_cen = "Cens."  # Count
    label_cnt_unc = "Uncens."  # Count
    label_k = "Rate"
    # label_e = r"$1/e$"
    label_int = "Area"
    label_kww = "Kohl."
    label_bur = "Burr"

    color_true = "tab:green"
    # color_cen = "tab:olive"
    # color_unc = "darkolivegreen"
    color_cnt_cen = "tab:orange"
    color_cnt_unc = "tab:red"
    color_k = "tab:brown"
    # color_e = "tab:pink"
    color_int = "tab:purple"
    color_kww = "tab:blue"
    color_bur = "tab:cyan"

    marker_true = "s"
    # marker_cen = "D"
    # marker_unc = "d"
    marker_cnt_cen = "H"
    marker_cnt_unc = "h"
    marker_k = "p"
    # marker_e = "<"
    marker_int = ">"
    marker_kww = "^"
    marker_bur = "v"

    xlabel = r"State Index"
    xlim = (np.min(states) - 0.5, np.max(states) + 0.5)
    alpha = 0.75
    cmap = plt.get_cmap()
    c_vals = np.arange(n_states)
    c_norm = max(1, n_states - 1)
    c_vals_normed = c_vals / c_norm
    colors = cmap(c_vals_normed)

    outfile = args.OUTFILE + ".pdf"
    mdt.fh.backup(outfile)
    with PdfPages(outfile) as pdf:
        # Plot distribution characteristics vs. state indices.
        ylabels = (
            "Average Lifetime / Frames",
            "Std. Dev. / Frames",
            "Skewness",
            "Excess Kurtosis",
            "Median / Frames",
        )
        for i, ylabel in enumerate(ylabels):
            if i == 0:
                offset_i_cnt = 0
            else:
                offset_i_cnt = 1
            fig, ax = plt.subplots(clear=True)
            if args.INFILE_PARAM is not None:
                # True lifetimes distribution.
                ax.errorbar(
                    states,
                    lts_true_characs[:, i],
                    yerr=None,
                    label=label_true,
                    color=color_true,
                    marker=marker_true,
                    alpha=alpha,
                )
            # Method 1 (censored counting).
            ax.errorbar(
                states,
                lts_cnt_cen_characs[:, i + offset_i_cnt],
                yerr=lts_cnt_cen_characs[:, i + 1] if i == 0 else None,
                label=label_cnt_cen,
                color=color_cnt_cen,
                marker=marker_cnt_cen,
                alpha=alpha,
            )
            # Method 2 (uncensored counting).
            ax.errorbar(
                states,
                lts_cnt_unc_characs[:, i + offset_i_cnt],
                yerr=lts_cnt_unc_characs[:, i + 1] if i == 0 else None,
                label=label_cnt_unc,
                color=color_cnt_unc,
                marker=marker_cnt_unc,
                alpha=alpha,
            )
            if i == 0:
                # Method 3 (inverse transition rate).
                ax.errorbar(
                    states,
                    lts_k,
                    yerr=None,
                    label=label_k,
                    color=color_k,
                    marker=marker_k,
                    alpha=alpha,
                )
                # # Method 4 (1/e criterion).
                # ax.errorbar(
                #     states,
                #     lts_e,
                #     yerr=None,
                #     label=label_e,
                #     color=color_e,
                #     marker=marker_e,
                #     alpha=alpha,
                # )
            # Method 5 (direct integral)
            ax.errorbar(
                states,
                lts_int_characs[:, i],
                yerr=None,
                label=label_int,
                color=color_int,
                marker=marker_int,
                alpha=alpha,
            )
            # Method 6 (integral of Kohlrausch fit).
            ax.errorbar(
                states,
                lts_kww_characs[:, i],
                yerr=None,
                label=label_kww,
                color=color_kww,
                marker=marker_kww,
                alpha=alpha,
            )
            # Method 7 (integral of Burr fit).
            ax.errorbar(
                states,
                lts_bur_characs[:, i],
                yerr=None,
                label=label_bur,
                color=color_bur,
                marker=marker_bur,
                alpha=alpha,
            )
            ax.set(xlabel=xlabel, ylabel=ylabel, xlim=xlim)
            ylim = ax.get_ylim()
            if i not in (2, 3) and ylim[0] < 0:
                ax.set_ylim(0, ylim[1])
            ax.xaxis.set_major_locator(MaxNLocator(integer=True))
            ax.set_xticks([], minor=True)
            ax.legend(ncol=3, **mdtplt.LEGEND_KWARGS_XSMALL)
            pdf.savefig()
            yd_min, yd_max = get_ydata_min_max(ax)
            if len(yd_min) > 0:
                # Set y axis to log scale.
                # Round y limits to next lower and higher power of ten.
                ylim = ax.get_ylim()
                ymin = 10 ** np.floor(np.log10(np.min(yd_min)))
                ymax = 10 ** np.ceil(np.log10(np.max(yd_max)))
                ax.set_ylim(
                    ymin if np.isfinite(ymin) else None,
                    ymax if np.isfinite(ymax) else None,
                )
                ax.set_yscale("log", base=10, subs=np.arange(2, 10))
                pdf.savefig()
            plt.close()

        # Plot number of min, max and number of samples for count
        # methods.
        ylabels = (
            "Min. Lifetime / Frames",
            "Max. Lifetime / Frames",
            "No. of Samples",
        )
        for i, ylabel in enumerate(ylabels):
            fig, ax = plt.subplots(clear=True)
            # Method 1 (censored counting).
            ax.plot(
                states,
                lts_cnt_cen_characs[:, 6 + i],
                label=label_cnt_cen,
                color=color_cnt_cen,
                marker=marker_cnt_cen,
                alpha=alpha,
            )
            # Method 2 (uncensored counting).
            ax.plot(
                states,
                lts_cnt_unc_characs[:, 6 + i],
                label=label_cnt_unc,
                color=color_cnt_unc,
                marker=marker_cnt_unc,
                alpha=alpha,
            )
            ax.set(xlabel=xlabel, ylabel=ylabel, xlim=xlim)
            ylim = ax.get_ylim()
            if ylim[0] < 0:
                ax.set_ylim(0, ylim[1])
            ax.xaxis.set_major_locator(MaxNLocator(integer=True))
            ax.set_xticks([], minor=True)
            ax.legend(**mdtplt.LEGEND_KWARGS_XSMALL)
            pdf.savefig()
            yd_min, yd_max = get_ydata_min_max(ax)
            if len(yd_min) > 0:
                # Set y axis to log scale (fit parameter delta).
                # Round y limits to next lower and higher power of ten.
                ylim = ax.get_ylim()
                ymin = 10 ** np.floor(np.log10(np.min(yd_min)))
                ymax = 10 ** np.ceil(np.log10(np.max(yd_max)))
                ax.set_ylim(
                    ymin if np.isfinite(ymin) else None,
                    ymax if np.isfinite(ymax) else None,
                )
                ax.set_yscale("log", base=10, subs=np.arange(2, 10))
                pdf.savefig()
            plt.close()

        # Plot fit parameters tau0 and beta.
        ylabels = (
            r"Fit Parameter $\tau_0$ / Frames",
            r"Fit Parameter $\beta$",
        )
        for i, ylabel in enumerate(ylabels):
            fig, ax = plt.subplots(clear=True)
            if args.INFILE_PARAM is not None:
                # True distribution.
                ax.errorbar(
                    states,
                    dist_params[:, i],
                    yerr=None,
                    label=label_true,
                    color=color_true,
                    marker=marker_true,
                    alpha=alpha,
                )
            # Method 6 (Kohlrausch fit).
            ax.errorbar(
                states,
                popt_kww[:, i],
                yerr=perr_kww[:, i],
                label=label_kww,
                color=color_kww,
                marker=marker_kww,
                alpha=alpha,
            )
            # Method 7 (Burr fit).
            ax.errorbar(
                states,
                popt_bur[:, i],
                yerr=perr_bur[:, i],
                label=label_bur,
                color=color_bur,
                marker=marker_bur,
                alpha=alpha,
            )
            ax.set(xlabel=xlabel, ylabel=ylabel, xlim=xlim)
            ylim = ax.get_ylim()
            if ylim[0] < 0:
                ax.set_ylim(0, ylim[1])
            ax.xaxis.set_major_locator(MaxNLocator(integer=True))
            ax.set_xticks([], minor=True)
            ax.legend(**mdtplt.LEGEND_KWARGS_XSMALL)
            pdf.savefig()
            yd_min, yd_max = get_ydata_min_max(ax)
            if len(yd_min) > 0:
                # Set y axis to log scale.
                # Round y limits to next lower and higher power of ten.
                ylim = ax.get_ylim()
                ymin = 10 ** np.floor(np.log10(np.min(yd_min)))
                ymax = 10 ** np.ceil(np.log10(np.max(yd_max)))
                ax.set_ylim(
                    ymin if np.isfinite(ymin) else None,
                    ymax if np.isfinite(ymax) else None,
                )
                ax.set_yscale("log", base=10, subs=np.arange(2, 10))
                pdf.savefig()
            plt.close()

        # Plot fit parameter delta.
        fig, ax = plt.subplots(clear=True)
        if args.INFILE_PARAM is not None:
            # True distribution.
            ax.errorbar(
                states,
                delta_true,
                yerr=None,
                label=label_true,
                color=color_true,
                marker=marker_true,
                alpha=alpha,
            )
        # Method 7 (Burr fit).
        ax.errorbar(
            states,
            delta_bur,
            yerr=delta_bur_sd,
            label=label_bur,
            color=color_bur,
            marker=marker_bur,
            alpha=alpha,
        )
        ax.set(xlabel=xlabel, ylabel=r"Fit Parameter $\delta$", xlim=xlim)
        ylim = ax.get_ylim()
        if ylim[0] < 0:
            ax.set_ylim(0, ylim[1])
        ax.xaxis.set_major_locator(MaxNLocator(integer=True))
        ax.set_xticks([], minor=True)
        ax.legend(**mdtplt.LEGEND_KWARGS_XSMALL)
        pdf.savefig()
        yd_min, yd_max = get_ydata_min_max(ax)
        if len(yd_min) > 0:
            # Set y axis to log scale (fit parameter delta).
            # Round y limits to next lower and higher power of ten.
            ylim = ax.get_ylim()
            ymin = 10 ** np.floor(np.log10(np.min(yd_min)))
            ymax = 10 ** np.ceil(np.log10(np.max(yd_max)))
            ax.set_ylim(
                ymin if np.isfinite(ymin) else None,
                ymax if np.isfinite(ymax) else None,
            )
            ax.set_yscale("log", base=10, subs=np.arange(2, 10))
            pdf.savefig()
        plt.close()

        # Plot goodness of fit quantities.
        ylabels = (r"Coeff. of Determ. $R^2$", "RMSE")
        for i, ylabel in enumerate(ylabels):
            fig, ax = plt.subplots(clear=True)
            if args.INFILE_PARAM is not None:
                # Remain probability to the true survival function.
                ax.plot(
                    states,
                    lts_true_rp_goodness[:, i],
                    label=r"$C(t)$",
                    color=color_true,
                    marker=marker_true,
                    alpha=alpha,
                )
            # Method 6 (Kohlrausch fit).
            ax.plot(
                states,
                lts_kww_fit_goodness[:, i],
                label=label_kww,
                color=color_kww,
                marker=marker_kww,
                alpha=alpha,
            )
            # Method 7 (Burr fit).
            ax.plot(
                states,
                lts_bur_fit_goodness[:, i],
                label=label_bur,
                color=color_bur,
                marker=marker_bur,
                alpha=alpha,
            )
            ax.set(xlabel=xlabel, ylabel=ylabel, xlim=xlim)
            ylim = ax.get_ylim()
            if ylim[0] < 0:
                ax.set_ylim(0, ylim[1])
            ax.xaxis.set_major_locator(MaxNLocator(integer=True))
            ax.set_xticks([], minor=True)
            ax.legend(**mdtplt.LEGEND_KWARGS_XSMALL)
            pdf.savefig()
            yd_min, yd_max = get_ydata_min_max(ax)
            if len(yd_min) > 0:
                # Set y axis to log scale (R^2 value of the fits).
                # Round `ymin` to next lower power of ten.
                ylim = ax.get_ylim()
                ymin = 10 ** np.floor(np.log10(np.min(yd_min)))
                if i == 0:
                    ymax = 2
                else:
                    ymax = 10 ** np.ceil(np.log10(np.max(yd_max)))
                ax.set_ylim(
                    ymin if np.isfinite(ymin) else None,
                    ymax if np.isfinite(ymax) else None,
                )
                ax.set_yscale("log", base=10, subs=np.arange(2, 10))
                pdf.savefig()
            plt.close()

        # Plot end of fit region.
        fig, ax = plt.subplots(clear=True)
        ax.plot(states, fit_stop - 1, marker="v")
        ax.set_yscale("log", base=10, subs=np.arange(2, 10))
        ax.set(xlabel=xlabel, ylabel="End of Fit Region / Frames", xlim=xlim)
        ax.xaxis.set_major_locator(MaxNLocator(integer=True))
        ax.set_xticks([], minor=True)
        pdf.savefig()
        plt.close()

        if args.INFILE_PARAM is not None:
            # Plot remain probabilities and true survival functions for
            # each state.
            fig, ax = plt.subplots(clear=True)
            ax.set_prop_cycle(color=colors)
            for i, rp in enumerate(remain_props.T):
                lines = ax.plot(
                    times,
                    rp,
                    label=r"$%d$" % states[i],
                    linewidth=1,
                    alpha=alpha,
                )
                ax.plot(
                    times,
                    lt_dists[i].sf(times),
                    label=r"True $S(t)$" if i == n_states - 1 else None,
                    linestyle="dashed",
                    color=lines[0].get_color(),
                    alpha=alpha,
                )
            ax.set(
                xlabel="Time / Frames",
                ylabel=r"Autocorrelation $C(t)$",
                xlim=(times[1], times[-1]),
                ylim=(0, 1),
            )
            ax.set_xscale("log", base=10, subs=np.arange(2, 10))
            legend = ax.legend(
                title="State Index",
                loc="upper right",
                ncol=2,
                **mdtplt.LEGEND_KWARGS_XSMALL,
            )
            legend.get_title().set_multialignment("center")
            pdf.savefig()
            plt.close()

            # Plot difference of the remain probabilities to the true
            # survival functions for each state.
            fig, ax = plt.subplots(clear=True)
            ax.set_prop_cycle(color=colors)
            for i, rp in enumerate(remain_props.T):
                res = lt_dists[i].sf(times) - rp
                ax.plot(times, res, label=r"$%d$" % states[i], alpha=alpha)
            ax.set(
                xlabel="Time / Frames",
                ylabel=r"$S(t) - C(t)$",
                xlim=(times[1], times[-1]),
            )
            ax.set_xscale("log", base=10, subs=np.arange(2, 10))
            legend = ax.legend(
                title="State Index",
                loc="lower right",
                ncol=2,
                **mdtplt.LEGEND_KWARGS_XSMALL,
            )
            legend.get_title().set_multialignment("center")
            pdf.savefig()
            plt.close()

        # Plot remain probabilities and Kohlrausch fits for each state.
        fig, ax = plt.subplots(clear=True)
        ax.set_prop_cycle(color=colors)
        for i, rp in enumerate(remain_props.T):
            times_fit = times[fit_start[i] : fit_stop[i]]
            fit = mdt.func.kww(times_fit, *popt_kww[i])
            lines = ax.plot(
                times, rp, label=r"$%d$" % states[i], linewidth=1, alpha=alpha
            )
            ax.plot(
                times_fit,
                fit,
                label=label_kww if i == n_states - 1 else None,
                linestyle="dashed",
                color=lines[0].get_color(),
                alpha=alpha,
            )
        ax.set(
            xlabel="Time / Frames",
            ylabel=r"Autocorrelation $C(t)$",
            xlim=(times[1], times[-1]),
            ylim=(0, 1),
        )
        ax.set_xscale("log", base=10, subs=np.arange(2, 10))
        legend = ax.legend(
            title="State Index",
            loc="upper right",
            ncol=2,
            **mdtplt.LEGEND_KWARGS_XSMALL,
        )
        legend.get_title().set_multialignment("center")
        pdf.savefig()
        plt.close()

        # Plot Kohlrausch fit residuals for each state.
        fig, ax = plt.subplots(clear=True)
        ax.set_prop_cycle(color=colors)
        for i, rp in enumerate(remain_props.T):
            times_fit = times[fit_start[i] : fit_stop[i]]
            fit = mdt.func.kww(times_fit, *popt_kww[i])
            res = rp[fit_start[i] : fit_stop[i]] - fit
            ax.plot(times_fit, res, label=r"$%d$" % states[i], alpha=alpha)
        ax.set(
            xlabel="Time / Frames",
            ylabel="Kohlrausch Fit Residuals",
            xlim=(times[1], times[-1]),
        )
        ax.set_xscale("log", base=10, subs=np.arange(2, 10))
        legend = ax.legend(
            title="State Index",
            loc="lower right",
            ncol=2,
            **mdtplt.LEGEND_KWARGS_XSMALL,
        )
        legend.get_title().set_multialignment("center")
        pdf.savefig()
        plt.close()

        # Plot remain probabilities and Burr fits for each state.
        fig, ax = plt.subplots(clear=True)
        ax.set_prop_cycle(color=colors)
        for i, rp in enumerate(remain_props.T):
            times_fit = times[fit_start[i] : fit_stop[i]]
            fit = mdt.func.burr12_sf_alt(times_fit, *popt_bur[i])
            lines = ax.plot(
                times, rp, label=r"$%d$" % states[i], linewidth=1, alpha=alpha
            )
            ax.plot(
                times_fit,
                fit,
                label=label_bur if i == n_states - 1 else None,
                linestyle="dashed",
                color=lines[0].get_color(),
                alpha=alpha,
            )
        ax.set(
            xlabel="Time / Frames",
            ylabel=r"Autocorrelation $C(t)$",
            xlim=(times[1], times[-1]),
            ylim=(0, 1),
        )
        ax.set_xscale("log", base=10, subs=np.arange(2, 10))
        legend = ax.legend(
            title="State Index",
            loc="upper right",
            ncol=2,
            **mdtplt.LEGEND_KWARGS_XSMALL,
        )
        legend.get_title().set_multialignment("center")
        pdf.savefig()
        plt.close()

        # Plot Burr fit residuals for each state.
        fig, ax = plt.subplots(clear=True)
        ax.set_prop_cycle(color=colors)
        for i, rp in enumerate(remain_props.T):
            times_fit = times[fit_start[i] : fit_stop[i]]
            fit = mdt.func.burr12_sf_alt(times_fit, *popt_bur[i])
            res = rp[fit_start[i] : fit_stop[i]] - fit
            ax.plot(times_fit, res, label=r"$%d$" % states[i], alpha=alpha)
        ax.set(
            xlabel="Time / Frames",
            ylabel="Burr Fit Residuals",
            xlim=(times[1], times[-1]),
        )
        ax.set_xscale("log", base=10, subs=np.arange(2, 10))
        legend = ax.legend(
            title="State Index",
            loc="lower right",
            ncol=2,
            **mdtplt.LEGEND_KWARGS_XSMALL,
        )
        legend.get_title().set_multialignment("center")
        pdf.savefig()
        plt.close()
    print("Created {}".format(outfile))
    print("Elapsed time:         {}".format(datetime.now() - timer))
    print("Current memory usage: {:.2f} MiB".format(mdt.rti.mem_usage(proc)))

    print("\n")
    print("{} done".format(os.path.basename(sys.argv[0])))
    print("Totally elapsed time: {}".format(datetime.now() - timer_tot))
    _cpu_time = timedelta(seconds=sum(proc.cpu_times()[:4]))
    print("CPU time:             {}".format(_cpu_time))
    print("CPU usage:            {:.2f} %".format(proc.cpu_percent()))
    print("Current memory usage: {:.2f} MiB".format(mdt.rti.mem_usage(proc)))
